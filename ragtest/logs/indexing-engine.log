15:24:15,401 graphrag.cli.index INFO Logging enabled at /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/logs/indexing-engine.log
15:24:23,422 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:24:24,605 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:24:24,609 graphrag.cli.index INFO Starting pipeline run. dry_run=False
15:24:24,609 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "deepseek-r1-250120",
            "encoding_model": "cl100k_base",
            "api_base": "https://ark.cn-beijing.volces.com/api/v3/",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "doubao-embedding-text-240715",
            "encoding_model": "cl100k_base",
            "api_base": "https://ark.cn-beijing.volces.com/api/v3/",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": false,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
15:24:24,610 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/output
15:24:24,611 graphrag.index.input.factory INFO loading input from root_dir=input
15:24:24,611 graphrag.index.input.factory INFO using file storage for input
15:24:24,612 graphrag.storage.file_pipeline_storage INFO search /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/input for files matching .*\.txt$
15:24:24,614 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
15:24:24,615 graphrag.index.input.util INFO Total number of unfiltered InputFileType.text rows: 1
15:24:24,618 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
15:24:24,629 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:24:24,655 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:24:24,657 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:24:24,675 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:26:03,135 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:27:00,133 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:27:00,205 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:27:00,207 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:27:00,235 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:27:00,237 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:27:00,273 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:27:00,275 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:27:00,277 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:27:00,309 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:27:00,311 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:27:00,312 graphrag.utils.storage INFO reading table from storage: communities.parquet
15:27:00,318 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 4
15:27:34,880 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:27:45,775 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:28:15,670 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:28:27,236 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:28:57,314 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:29:10,465 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:29:49,540 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:30:36,14 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:30:36,89 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:30:36,92 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:30:36,94 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:30:36,96 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:30:36,97 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
15:30:36,100 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
15:30:36,100 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
15:30:36,129 graphrag.index.operations.embed_text.strategies.openai INFO embedding 2 inputs via 2 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
15:30:36,293 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:30:36,373 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
15:30:36,374 graphrag.index.operations.embed_text.strategies.openai INFO embedding 4 inputs via 4 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
15:30:36,447 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:30:36,490 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
15:30:36,491 graphrag.index.operations.embed_text.strategies.openai INFO embedding 1 inputs via 1 snippets using 1 batches. max_batch_size=16, batch_max_tokens=8191
15:30:36,556 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:30:36,593 graphrag.cli.index INFO All workflows completed successfully.
15:32:42,75 graphrag.cli.index INFO Logging enabled at /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/logs/indexing-engine.log
15:32:50,823 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:32:50,985 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:32:50,990 graphrag.cli.index INFO Starting pipeline run. dry_run=False
15:32:50,992 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "deepseek-r1-250120",
            "encoding_model": "cl100k_base",
            "api_base": "https://ark.cn-beijing.volces.com/api/v3/",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "doubao-embedding-text-240715",
            "encoding_model": "cl100k_base",
            "api_base": "https://ark.cn-beijing.volces.com/api/v3/",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
15:32:50,992 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/output
15:32:50,993 graphrag.index.input.factory INFO loading input from root_dir=input
15:32:50,993 graphrag.index.input.factory INFO using file storage for input
15:32:50,994 graphrag.storage.file_pipeline_storage INFO search /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/input for files matching .*\.txt$
15:32:50,997 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
15:32:50,997 graphrag.index.input.util INFO Total number of unfiltered InputFileType.text rows: 1
15:32:51,0 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
15:32:51,11 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:32:51,33 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:32:51,35 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:32:51,55 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:33:32,984 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:33:33,54 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:33:33,56 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:33:33,86 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:33:33,88 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:33:33,119 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:33:33,120 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:33:33,122 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:33:33,149 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:33:33,151 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:33:33,153 graphrag.utils.storage INFO reading table from storage: communities.parquet
15:33:33,158 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 3
15:34:26,398 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:35:02,669 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:35:52,445 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:36:31,902 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 112, in try_receive_json
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/cached.py", line 115, in invoke
    result = await delegate(prompt, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/rate_limiter.py", line 75, in invoke
    result = await delegate(prompt, **args)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 126, in _decorator_target
    output = await self._execute_llm(prompt, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_text_chat_llm.py", line 157, in _execute_llm
    completion = await self._client.chat.completions.create(
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/openai/resources/chat/completions/completions.py", line 2028, in create
    return await self._post(
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/openai/_base_client.py", line 1742, in post
    return await self.request(cast_to, opts, stream=stream, stream_cls=stream_cls)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/openai/_base_client.py", line 1484, in request
    response = await self._client.send(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpx/_client.py", line 1629, in send
    response = await self._send_handling_auth(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpx/_client.py", line 1657, in _send_handling_auth
    response = await self._send_handling_redirects(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpx/_client.py", line 1694, in _send_handling_redirects
    response = await self._send_single_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpx/_client.py", line 1730, in _send_single_request
    response = await transport.handle_async_request(request)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpx/_transports/default.py", line 394, in handle_async_request
    resp = await self._pool.handle_async_request(req)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpcore/_async/connection_pool.py", line 256, in handle_async_request
    raise exc from None
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpcore/_async/connection_pool.py", line 236, in handle_async_request
    response = await connection.handle_async_request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpcore/_async/http_proxy.py", line 343, in handle_async_request
    return await self._connection.handle_async_request(request)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpcore/_async/http11.py", line 136, in handle_async_request
    raise exc
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpcore/_async/http11.py", line 106, in handle_async_request
    ) = await self._receive_response_headers(**kwargs)
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpcore/_async/http11.py", line 177, in _receive_response_headers
    event = await self._receive_event(timeout=timeout)
            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpcore/_async/http11.py", line 217, in _receive_event
    data = await self._network_stream.read(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/httpcore/_backends/anyio.py", line 35, in read
    return await self._stream.receive(max_bytes=max_bytes)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/anyio/streams/tls.py", line 219, in receive
    data = await self._call_sslobject_method(self._ssl_object.read, max_bytes)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/anyio/streams/tls.py", line 162, in _call_sslobject_method
    data = await self.transport_stream.receive()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/anyio/_backends/_asyncio.py", line 1254, in receive
    await self._protocol.read_event.wait()
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/asyncio/locks.py", line 212, in wait
    await fut
asyncio.exceptions.CancelledError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:36:31,912 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:36:31,913 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 0
15:40:21,921 graphrag.cli.index INFO Logging enabled at /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/logs/indexing-engine.log
15:40:28,765 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:40:29,361 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:40:29,366 graphrag.cli.index INFO Starting pipeline run. dry_run=False
15:40:29,367 graphrag.cli.index INFO Using default configuration: {
    "root_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest",
    "models": {
        "default_chat_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_chat",
            "model": "deepseek-r1-250120",
            "encoding_model": "cl100k_base",
            "api_base": "https://ark.cn-beijing.volces.com/api/v3/",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        },
        "default_embedding_model": {
            "api_key": "==== REDACTED ====",
            "auth_type": "api_key",
            "type": "openai_embedding",
            "model": "doubao-embedding-text-240715",
            "encoding_model": "cl100k_base",
            "api_base": "https://ark.cn-beijing.volces.com/api/v3/",
            "api_version": null,
            "deployment_name": null,
            "proxy": null,
            "audience": null,
            "model_supports_json": true,
            "request_timeout": 180.0,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "retry_strategy": "native",
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "concurrent_requests": 25,
            "async_mode": "threaded",
            "responses": null,
            "max_tokens": null,
            "temperature": 0,
            "max_completion_tokens": null,
            "reasoning_effort": null,
            "top_p": 1,
            "n": 1,
            "frequency_penalty": 0.0,
            "presence_penalty": 0.0
        }
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "text_column": "text",
        "title_column": null,
        "metadata": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": "tokens",
        "encoding_model": "cl100k_base",
        "prepend_metadata": false,
        "chunk_size_includes_metadata": false
    },
    "output": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "outputs": null,
    "update_index_output": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/update_output",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null,
        "cosmosdb_account_url": null
    },
    "reporting": {
        "type": "file",
        "base_dir": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/logs",
        "storage_account_blob_url": null
    },
    "vector_store": {
        "default_vector_store": {
            "type": "lancedb",
            "db_uri": "/Users/pandegong/Downloads/\u534e\u6b63\u4ea7\u4e1a\u5927\u8111\u77e5\u8bc6\u5e93/ragtest/output/lancedb",
            "url": null,
            "audience": null,
            "container_name": "==== REDACTED ====",
            "database_name": null,
            "overwrite": true
        }
    },
    "workflows": null,
    "embed_text": {
        "model_id": "default_embedding_model",
        "vector_store_id": "default_vector_store",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "names": [],
        "strategy": null
    },
    "extract_graph": {
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_graph.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null
    },
    "summarize_descriptions": {
        "model_id": "default_chat_model",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "max_input_tokens": 4000,
        "strategy": null
    },
    "extract_graph_nlp": {
        "normalize_edge_weights": true,
        "text_analyzer": {
            "extractor_type": "regex_english",
            "model_name": "en_core_web_md",
            "max_word_length": 15,
            "word_delimiter": " ",
            "include_named_entities": true,
            "exclude_nouns": [
                "stuff",
                "thing",
                "things",
                "bunch",
                "bit",
                "bits",
                "people",
                "person",
                "okay",
                "hey",
                "hi",
                "hello",
                "laughter",
                "oh"
            ],
            "exclude_entity_tags": [
                "DATE"
            ],
            "exclude_pos_tags": [
                "DET",
                "PRON",
                "INTJ",
                "X"
            ],
            "noun_phrase_tags": [
                "PROPN",
                "NOUNS"
            ],
            "noun_phrase_grammars": {
                "PROPN,PROPN": "PROPN",
                "NOUN,NOUN": "NOUNS",
                "NOUNS,NOUN": "NOUNS",
                "ADJ,ADJ": "ADJ",
                "ADJ,NOUN": "NOUNS"
            }
        },
        "concurrent_requests": 25
    },
    "prune_graph": {
        "min_node_freq": 2,
        "max_node_freq_std": null,
        "min_node_degree": 1,
        "max_node_degree_std": null,
        "min_edge_weight_pct": 40.0,
        "remove_ego_nodes": true,
        "lcc_only": false
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "use_lcc": true,
        "seed": 3735928559
    },
    "extract_claims": {
        "enabled": false,
        "model_id": "default_chat_model",
        "prompt": "prompts/extract_claims.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null
    },
    "community_reports": {
        "model_id": "default_chat_model",
        "graph_prompt": "prompts/community_report_graph.txt",
        "text_prompt": "prompts/community_report_text.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "embed_graph": {
        "enabled": false,
        "dimensions": 1536,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "use_lcc": true
    },
    "umap": {
        "enabled": false
    },
    "snapshots": {
        "embeddings": false,
        "graphml": true,
        "raw_graph": false
    },
    "local_search": {
        "prompt": "prompts/local_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "text_unit_prop": 0.5,
        "community_prop": 0.15,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "max_context_tokens": 12000
    },
    "global_search": {
        "map_prompt": "prompts/global_search_map_system_prompt.txt",
        "reduce_prompt": "prompts/global_search_reduce_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "knowledge_prompt": "prompts/global_search_knowledge_system_prompt.txt",
        "max_context_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_length": 1000,
        "reduce_max_length": 2000,
        "dynamic_search_threshold": 1,
        "dynamic_search_keep_parent": false,
        "dynamic_search_num_repeats": 1,
        "dynamic_search_use_summary": false,
        "dynamic_search_max_level": 2
    },
    "drift_search": {
        "prompt": "prompts/drift_search_system_prompt.txt",
        "reduce_prompt": "prompts/drift_search_reduce_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "data_max_tokens": 12000,
        "reduce_max_tokens": null,
        "reduce_temperature": 0,
        "reduce_max_completion_tokens": null,
        "concurrency": 32,
        "drift_k_followups": 20,
        "primer_folds": 5,
        "primer_llm_max_tokens": 12000,
        "n_depth": 3,
        "local_search_text_unit_prop": 0.9,
        "local_search_community_prop": 0.1,
        "local_search_top_k_mapped_entities": 10,
        "local_search_top_k_relationships": 10,
        "local_search_max_data_tokens": 12000,
        "local_search_temperature": 0,
        "local_search_top_p": 1,
        "local_search_n": 1,
        "local_search_llm_max_gen_tokens": null,
        "local_search_llm_max_gen_completion_tokens": null
    },
    "basic_search": {
        "prompt": "prompts/basic_search_system_prompt.txt",
        "chat_model_id": "default_chat_model",
        "embedding_model_id": "default_embedding_model",
        "k": 10,
        "max_context_tokens": 12000
    }
}
15:40:29,368 graphrag.storage.file_pipeline_storage INFO Creating file storage at /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/output
15:40:29,368 graphrag.index.input.factory INFO loading input from root_dir=input
15:40:29,368 graphrag.index.input.factory INFO using file storage for input
15:40:29,369 graphrag.storage.file_pipeline_storage INFO search /Users/pandegong/Downloads/华正产业大脑知识库/ragtest/input for files matching .*\.txt$
15:40:29,371 graphrag.index.input.util INFO Found 1 InputFileType.text files, loading 1
15:40:29,372 graphrag.index.input.util INFO Total number of unfiltered InputFileType.text rows: 1
15:40:29,375 graphrag.index.run.run_pipeline INFO Final # of rows loaded: 1
15:40:29,385 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:40:29,441 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:40:29,443 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:40:29,461 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:41:10,517 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:12,402 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:18,661 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:22,187 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:23,485 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:31,453 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:32,530 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:40,580 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:51,607 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:53,518 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:55,161 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:55,980 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:41:57,937 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:01,747 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:06,325 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:07,820 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:11,34 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:15,650 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:17,805 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:19,707 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:24,561 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:31,134 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:34,97 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:41,526 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:42,936 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:45,646 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:48,224 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:50,93 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:52,402 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:52,618 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:55,378 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:56,559 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:59,276 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:42:59,917 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:00,903 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:03,358 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:05,317 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:07,521 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:08,72 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:08,260 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:09,402 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:21,144 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:24,934 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:40,655 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:44,796 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:46,982 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:43:56,765 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:10,817 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:12,814 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:14,426 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:14,457 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:14,871 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:17,602 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:22,915 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:24,258 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:27,840 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:30,752 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:32,654 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:35,544 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:38,76 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:41,99 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:41,569 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:51,108 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:52,757 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:53,485 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:44:57,230 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:45:05,525 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:45:14,332 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:45:23,103 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:45:33,207 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:45:33,340 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:45:39,282 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:45:42,970 openai._base_client INFO Retrying request to /chat/completions in 0.383169 seconds
15:45:56,744 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:46:00,521 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:46:04,917 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:46:06,428 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:46:09,835 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:46:41,895 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:46:46,13 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:46:53,99 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:47:06,149 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:47:17,161 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:47:26,430 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:47:49,264 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:03,413 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:06,506 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:07,933 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:07,999 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:08,958 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:09,701 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:10,335 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:11,209 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:12,741 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:12,780 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:12,854 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:14,71 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:14,787 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:16,434 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:16,758 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:18,880 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:19,265 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:19,400 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:19,625 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:20,490 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:20,661 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:21,889 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:24,590 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:24,918 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:25,867 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:27,358 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:33,309 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:33,513 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:36,301 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:36,352 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:37,294 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:37,715 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:37,813 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:40,498 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:45,618 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:45,839 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:46,853 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:48:51,854 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:03,921 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:05,154 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:07,515 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:07,756 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:07,840 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:08,328 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:09,207 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:09,869 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:10,585 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:10,993 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:11,470 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:11,583 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:11,637 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:13,579 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:14,679 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:14,681 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:14,772 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:15,204 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:15,602 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:15,749 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:16,361 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:20,50 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:21,326 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:21,799 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:24,6 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:25,755 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:25,912 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:26,330 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:26,630 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:26,644 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:27,322 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:30,63 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:30,246 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:30,398 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:30,609 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:31,274 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:31,678 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:32,194 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:33,213 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:33,886 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:38,745 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:38,775 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:41,9 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:49:41,92 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:49:41,95 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:49:41,135 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:49:41,138 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:49:41,202 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:49:41,204 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:49:41,206 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:49:41,250 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:49:41,252 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:49:41,254 graphrag.utils.storage INFO reading table from storage: communities.parquet
15:49:41,260 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=1 => 196
15:49:41,391 graphrag.index.operations.summarize_communities.graph_context.context_builder INFO Number of nodes at level=0 => 211
15:50:10,763 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:13,927 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:16,802 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:17,363 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:18,843 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:22,460 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:22,984 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:23,696 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:23,699 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:24,312 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:25,254 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:25,431 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:25,832 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:27,583 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:28,369 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:32,591 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:32,595 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:34,273 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:35,217 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:35,986 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:38,164 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:40,184 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:44,129 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:45,174 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:45,509 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:50,367 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:54,51 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:55,18 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:56,106 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:50:57,286 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:00,456 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:01,995 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:02,678 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:05,272 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:09,574 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:10,453 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:13,686 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:17,968 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:18,481 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:22,985 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:23,179 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:24,53 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:26,233 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:27,427 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:27,900 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:28,824 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:32,509 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:32,863 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:34,887 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:35,510 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:37,71 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:41,199 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:41,372 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:47,664 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:48,997 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:50,433 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:52,871 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:54,74 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:54,344 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:56,677 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:57,593 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:51:57,594 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:00,18 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:00,287 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:02,995 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:03,4 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:04,50 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:04,243 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:09,580 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:09,595 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Scrooge's Room and Wandering Spirits Community",
    "summary": "The community centers on Scrooge's Room, where Ebenezer Scrooge experiences supernatural visions and personal redemption. The Wandering Spirits manifest at the room's window, directly influencing Scrooge's transformative journey. The window serves as a critical interface between the physical space and supernatural entities.",
    "rating": 2.0,
    "rating_explanation": "The impact severity rating is low due to the fictional and allegorical nature of the entities, with no direct real-world operational or reputational risks.",
    "findings": [
        {
            "summary": "Scrooge's Room as the focal point of transformation",
            "explanation": "Scrooge's Room (Entity 200) is the physical and symbolic heart of the community, serving as the setting for Scrooge's redemption. The room's connection to Ebenezer Scrooge through Relationship 324 demonstrates its critical role in his character development. This confined space becomes a theater for supernatural intervention and self-realization. [Data: Entities (200); Relationships (324)]"
        },
        {
            "summary": "Wandering Spirits as supernatural catalysts",
            "explanation": "The Wandering Spirits (Entity 198) appear at Scrooge's window (Entity 204) to deliver transformative visions, as evidenced by Relationships 332 and 333. These spirits function as narrative devices that bridge the mundane and supernatural realms, directly enabling Scrooge's moral reckoning. Their persistent appearances suggest an intentional supernatural influence pattern. [Data: Entities (198, 204); Relationships (332, 333)]"
        },
        {
            "summary": "Window as liminal space",
            "explanation": "The Window (Entity 204) serves as a threshold where supernatural manifestations (Relationship 333) intersect with Scrooge's physical environment. This architectural feature enables the Wandering Spirits to visually communicate with Scrooge while maintaining spatial separation, creating tension between observation and interaction. [Data: Entities (204); Relationships (332, 333)]"
        },
        {
            "summary": "Redemption narrative framework",
            "explanation": "The community's dynamics follow a structured redemption arc centered on Scrooge's awakening in his room (Relationship 324). This narrative framework positions the physical space as both prison and sanctuary, with the supernatural elements serving as forced introspection mechanisms. [Data: Relationships (324)]"
        },
        {
            "summary": "Supernatural influence patterns",
            "explanation": "The Wandering Spirits demonstrate targeted apparition behavior, appearing specifically at Scrooge's window (Relationship 332) rather than other locations. This suggests either geographical anchoring to the room or intentional focus on Scrooge as the sole observer. The spirits' visibility through the window implies designed perceptibility constraints. [Data: Entities (198, 204); Relationships (332)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:09,605 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:09,605 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 18.0
15:52:10,296 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:10,306 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Sultan’s Groom, Genii, and Damascus Story Characters",
    "summary": "The community centers around interconnected story characters from Scrooge’s childhood memories. The Sultan’s Groom is a pivotal entity, linked to supernatural Genii who overturned it and the city of Damascus, where a character was placed asleep at the gate. Valentine and Orson, brother characters, are connected to the Sultan’s Groom narrative, forming a web of fantastical tales.",
    "rating": 1.0,
    "rating_explanation": "The impact severity rating is minimal as these entities are fictional story elements with no direct real-world implications.",
    "findings": [
        {
            "summary": "Sultan’s Groom as the narrative anchor",
            "explanation": "The Sultan’s Groom is the central entity, directly linked to the Genii and Damascus. Its role in the story—being overturned by supernatural forces and tied to a specific location—highlights its narrative significance. This character’s connections suggest a thematic focus on conflict and the supernatural in Scrooge’s recalled tales. [Data: Entities (84), Relationships (110, 111)]"
        },
        {
            "summary": "Genii’s supernatural influence",
            "explanation": "The Genii, supernatural beings, are critical to the story’s conflict, as they overturn the Sultan’s Groom. Their role underscores the fantastical elements of Scrooge’s memories and may reflect his childhood fascination with mythical forces. [Data: Entities (85), Relationships (110)]"
        },
        {
            "summary": "Damascus as a symbolic location",
            "explanation": "Damascus is tied to the Sultan’s Groom narrative, serving as the setting where a character is “put down asleep at the gate.” This detail adds a layer of mystery and reinforces the story’s emphasis on displacement or vulnerability. [Data: Entities (88), Relationships (111)]"
        },
        {
            "summary": "Valentine and Orson’s thematic connection",
            "explanation": "Valentine and Orson, brother characters, are linked to the Sultan’s Groom story, suggesting interconnected tales of adventure and familial bonds in Scrooge’s recollections. Their inclusion broadens the narrative scope of the community. [Data: Entities (83), Relationships (109)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:10,314 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:10,314 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 17.0
15:52:11,806 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:13,987 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:15,316 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:23,38 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:23,140 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:24,205 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:24,219 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Little Fan's Homecoming and Coach Transport",
    "summary": "The community centers on Little Fan's efforts to reunite Scrooge with their family during Christmas via the Homecoming event, facilitated by a coach arranged by their father. The relationships highlight Little Fan's pivotal role in initiating the event and the coach's logistical support.",
    "rating": 2.5,
    "rating_explanation": "The impact severity rating is low due to the personal, familial nature of the event with limited broader societal or operational implications.",
    "findings": [
        {
            "summary": "Little Fan's pivotal role in initiating the Homecoming",
            "explanation": "Little Fan is the central figure in this community, described as delicate and kind-hearted. She initiates and facilitates Scrooge's Homecoming from school, demonstrating her agency in reuniting the family. This underscores her emotional significance and operational role in the event. [Data: Entities (91), Relationships (121)]"
        },
        {
            "summary": "Homecoming as a catalyst for familial reconciliation",
            "explanation": "The Homecoming event marks a critical moment of familial reconciliation, occurring after the father's change of heart. It serves as the community's primary event, directly connecting Little Fan, Scrooge, and the coach. The event's success hinges on both emotional intent (Little Fan's kindness) and logistical execution (the coach). [Data: Entities (95), Relationships (121, 126)]"
        },
        {
            "summary": "Coach's logistical importance in the Homecoming",
            "explanation": "The coach, arranged by the father, is the transportation method enabling Scrooge's journey home. Its role is purely logistical but essential, reflecting the father's indirect involvement in facilitating reconciliation. The coach's inclusion highlights the practical steps taken to mend familial ties. [Data: Entities (97), Relationships (126)]"
        },
        {
            "summary": "Father's indirect influence on the community dynamics",
            "explanation": "Though not a direct entity, the father's change of heart and arrangement of the coach are pivotal to the Homecoming. This underscores the theme of reconciliation driven by off-screen familial decisions, indirectly shaping the community's structure. [Data: Entities (95, 97)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:24,227 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:24,227 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 25.0
15:52:29,344 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:30,237 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:31,902 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:31,913 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Sea, Lighthouse, and Christmas Celebration Community",
    "summary": "The community centers around the turbulent Sea, which connects the Lighthouse, Reef, and Ship. The Lighthouse, built on the Reef, and sailors on the Sea and Ship maintain Christmas traditions despite harsh conditions, fostering camaraderie and remembrance. Relationships highlight shared celebrations and the physical interdependence of these entities.",
    "rating": 3.5,
    "rating_explanation": "The impact severity rating is low due to the community's focus on maintaining traditions and cooperation without indications of conflict or risk.",
    "findings": [
        {
            "summary": "Central role of the Sea in connecting entities",
            "explanation": "The Sea is the most interconnected entity, directly linked to the Ship, Reef, and Christmas celebrations. Sailors on the Sea uphold Christmas traditions, fostering kindness and remembrance, which underscores its role as both a physical and symbolic hub. The turbulent nature of the Sea suggests environmental challenges, yet its centrality highlights resilience. [Data: Entities (145); Relationships (226, 227, 225)]"
        },
        {
            "summary": "Lighthouse as a focal point of camaraderie",
            "explanation": "The Lighthouse, manned by two keepers, is built on the Reef and serves as a site for Christmas celebrations involving fire and song. Its relationship with Christmas emphasizes communal bonding despite isolation. The Lighthouse’s structural reliance on the Reef and proximity to the Sea underscores its vulnerability to environmental conditions. [Data: Entities (143); Relationships (223, 225)]"
        },
        {
            "summary": "Reef’s foundational and environmental significance",
            "explanation": "The Reef provides the foundation for the Lighthouse and is surrounded by the turbulent Sea. Its description as 'dismal' and composed of sunken rocks highlights its hazardous nature, which may amplify risks for nearby entities. However, its role in anchoring the Lighthouse demonstrates its critical structural importance. [Data: Entities (144); Relationships (225)]"
        },
        {
            "summary": "Ship’s navigation and Christmas traditions",
            "explanation": "The Ship navigates the Sea while crew members observe Christmas traditions, reflecting their commitment to maintaining morale and unity amid harsh conditions. This relationship suggests a cultural emphasis on perseverance and shared values. [Data: Entities (146); Relationships (227)]"
        },
        {
            "summary": "Christmas as a unifying theme",
            "explanation": "Christmas celebrations are a common thread between the Sea’s sailors and the Lighthouse keepers, fostering kindness and camaraderie. These traditions mitigate the challenges posed by the environment, emphasizing the community’s reliance on shared rituals. [Data: Relationships (226, 223)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:31,919 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:31,920 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 27.0
15:52:32,415 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:34,54 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:39,773 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:40,709 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:42,961 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:44,701 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:44,710 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Ebenezer Scrooge and Jacob Marley Redemption Network",
    "summary": "The community centers on Ebenezer Scrooge, whose transformative journey is driven by relationships with Jacob Marley, supernatural entities, and key events. Scrooge’s business ties to Marley, interactions with the Ghost of Christmas Future, and decisions like raising Bob Cratchit’s salary and purchasing a turkey for the Cratchit family define this network. Marley’s posthumous warnings and the spirits’ interventions catalyze Scrooge’s redemption, impacting his business, employees, and broader community.",
    "rating": 6.5,
    "rating_explanation": "The impact severity is moderate due to Scrooge’s profound personal transformation and its cascading effects on employee welfare and community goodwill.",
    "findings": [
        {
            "summary": "Scrooge’s pivotal relationship with Jacob Marley",
            "explanation": "Jacob Marley, Scrooge’s deceased business partner, serves as the catalyst for Scrooge’s redemption. Their shared history of greed and Marley’s spectral warning about Scrooge’s potential eternal torment establish the narrative stakes. Marley’s ghost explicitly links Scrooge’s fate to his capacity for change, framing their relationship as both a cautionary tale and a bridge to redemption. This dynamic underscores themes of accountability and the lingering consequences of past actions. [Data: Entities (15, 201); Relationships (70)]"
        },
        {
            "summary": "Scrooge’s transformative financial decisions",
            "explanation": "Scrooge’s unexpected salary raise for Bob Cratchit and purchase of a turkey for the Cratchit family signal his moral awakening. These acts directly reverse his earlier reputation as a miser, demonstrating a shift from exploitation to generosity. The salary raise and gift carry symbolic and practical weight, improving the Cratchit family’s immediate well-being and signaling broader societal impacts of personal redemption. [Data: Entities (199, 210); Relationships (323, 342)]"
        },
        {
            "summary": "Role of the Ghost of Christmas Future",
            "explanation": "The Ghost of Christmas Future’s grim visions of Scrooge’s lonely death and the Cratchits’ mourning for Tiny Tim compel Scrooge to vow behavioral change. This spirit’s influence is critical in solidifying Scrooge’s commitment to empathy, as it confronts him with irreversible consequences rather than nostalgic or emotional appeals. The relationship highlights the power of fear and foresight in moral transformation. [Data: Entities (201); Relationships (325)]"
        },
        {
            "summary": "Scrooge & Marley as a nexus of influence",
            "explanation": "The Scrooge & Marley business office represents both the legacy of greed and the potential for ethical reform. As Scrooge’s workplace and primary financial asset, its operations directly affect Bob Cratchit’s livelihood. Scrooge’s post-redemption management of the firm suggests a shift from exploitative practices to equitable treatment, with implications for employee welfare and community trust. [Data: Entities (211); Relationships (343)]"
        },
        {
            "summary": "Poulterer’s turkey as a symbolic gesture",
            "explanation": "Scrooge’s anonymous purchase of a large turkey from the Poulterer’s shop symbolizes his rejection of frugality and embrace of generosity. This act contrasts with his earlier refusal to donate to charity, marking a tangible step toward reintegrating into the community. The transaction also indirectly benefits local commerce, illustrating how personal redemption can ripple through economic networks. [Data: Entities (199); Relationships (323)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:44,715 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:44,715 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 12.0
15:52:46,750 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:47,359 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:47,374 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "The Phantom, Jacob Marley's Death, and the Merchants",
    "summary": "The community centers on the death of Jacob Marley and its aftermath, involving The Phantom, who guides Scrooge through moral lessons tied to Marley's death. The Merchants are cynically connected to Marley's funeral, highlighting his lack of personal connections. The Phantom’s interactions and the Merchants’ behavior underscore themes of morality and social indifference.",
    "rating": 4.5,
    "rating_explanation": "The impact severity rating is moderate due to the moral implications of The Phantom's guidance and the Merchants' cynical attitudes toward Marley's death and funeral.",
    "findings": [
        {
            "summary": "The Phantom's moral guidance",
            "explanation": "The Phantom serves as a spiritual guide, showing Scrooge conversations about Jacob Marley's death to impart moral lessons. This entity is central to the community's narrative, framing the death and funeral as catalysts for introspection. The Phantom’s role suggests a focus on ethical consequences and personal accountability. [Data: Entities (173), Relationships (269)]"
        },
        {
            "summary": "Jacob Marley's death as a pivotal event",
            "explanation": "The death of Jacob Marley, Scrooge's former business partner, is a focal point of discussion among Merchants. This event directly triggers his sparsely attended funeral, emphasizing Marley's isolation. The death’s prominence in the community underscores themes of legacy and social neglect. [Data: Entities (174), Relationships (269, 272)]"
        },
        {
            "summary": "Funeral of Jacob Marley highlights social indifference",
            "explanation": "Marley's funeral is mockingly discussed by Merchants, who prioritize free lunch over paying respects. This reflects the community’s cynical dynamics and Marley's lack of meaningful personal connections. The event underscores the Merchants' transactional mindset. [Data: Entities (176), Relationships (272, 275)]"
        },
        {
            "summary": "Merchants' cynical engagement with the funeral",
            "explanation": "Merchants are linked to the funeral through their self-interested discussions about attending only if food is provided. Their behavior highlights a lack of empathy and reinforces the community’s themes of moral decay. This relationship is critical to understanding the social dynamics at play. [Data: Entities (178), Relationships (275)]"
        },
        {
            "summary": "Causal link between death and funeral",
            "explanation": "Marley's death directly causes his funeral, creating a narrative chain that ties The Phantom, Merchants, and Scrooge together. This relationship underscores the inevitability of consequences and the community’s focus on cause and effect. [Data: Relationships (272)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:47,381 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:47,381 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 22.0
15:52:48,379 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:49,822 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:49,836 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Fred's Christmas Dinner Party and Festive Attendees",
    "summary": "The community centers on Fred’s Christmas Dinner Party, a festive gathering where Fred reconciles with his uncle Ebenezer Scrooge. Key entities include Fred (the host), Topper (a charismatic guest), the Plump Sister (an active participant in games), and the Niece by Marriage (Fred’s wife). Relationships highlight Fred’s advocacy for Christmas joy, Topper’s playful role in festivities, and the Plump Sister’s engagement in the Blind Man’s-Buff game. The event underscores themes of communal celebration and redemption.",
    "rating": 2.5,
    "rating_explanation": "The impact severity is low, as the community represents a social gathering with minimal external risk but thematic narrative significance.",
    "findings": [
        {
            "summary": "Fred as the central host and advocate for Christmas",
            "explanation": "Fred is the core entity, hosting the Christmas Dinner Party and passionately advocating for the joy of Christmas. His role as a reconciler with Scrooge and organizer of the event positions him as the community’s emotional anchor. The party’s warmth contrasts with Scrooge’s earlier isolation, symbolizing redemption. [Data: Entities (26), Relationships (232, 349)]"
        },
        {
            "summary": "Topper’s lively and mischievous participation",
            "explanation": "Topper is a key attendee, contributing to the party’s energy through games like Blind Man’s-Buff and musical antics. His flirtatious interest in the Plump Sister’s sibling and collaboration with Fred highlight his role in fostering camaraderie. [Data: Entities (149), Relationships (234)]"
        },
        {
            "summary": "Plump Sister’s spirited engagement in games",
            "explanation": "The Plump Sister actively participates in Blind Man’s-Buff, showcasing her sociable nature. Her perceptiveness during a guessing game involving Scrooge suggests familiarity with Fred’s anecdotes, reinforcing the party’s role in bridging familial divides. [Data: Entities (151), Relationships (238)]"
        },
        {
            "summary": "Christmas Dinner Party as the community’s focal event",
            "explanation": "The Christmas Dinner Party serves as the physical and thematic hub, linking Fred, his wife, and guests. Its depiction as a reconciliatory space for Scrooge underscores its narrative importance in highlighting communal joy. [Data: Entities (209), Relationships (349)]"
        },
        {
            "summary": "Blind Man’s-Buff as a unifying game",
            "explanation": "The Blind Man’s-Buff game fosters interaction between Topper and the Plump Sister, symbolizing the playful dynamics of the gathering. Its inclusion reflects traditional festive activities that strengthen social bonds. [Data: Entities (153), Relationships (238)]"
        },
        {
            "summary": "Niece by Marriage’s supportive role",
            "explanation": "Fred’s wife (the Niece by Marriage) co-hosts the dinner, though her limited description suggests a secondary role compared to Fred and the guests. Her participation reinforces the familial aspect of the event. [Data: Entities (212), Relationships (349)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:49,848 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:49,851 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 23.0
15:52:50,962 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:53,101 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:53,110 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Jacob Marley, Ebenezer Scrooge, and the Redemption Network",
    "summary": "The community centers on Jacob Marley’s spectral intervention to redeem Ebenezer Scrooge, his former business partner. Marley’s ghost (Entity 10) initiates Scrooge’s transformation by warning him of spiritual consequences and orchestrating visits from the Second Spirit (Entity 110). Key entities include the Counting-House (Entity 63), which Scrooge now operates, and Christmas Eve (Entity 31), the temporal anchor for Marley’s visitation and Scrooge’s reckoning. Relationships highlight Marley’s influence over Scrooge (Relationship 11), the Second Spirit’s role (Relationship 155), and speculative ties to Marley’s Company (Relationship 271).",
    "rating": 6.5,
    "rating_explanation": "The impact severity is high due to the profound personal and societal consequences of Scrooge’s potential redemption or continued moral failure.",
    "findings": [
        {
            "summary": "Jacob Marley as the catalyst for Scrooge’s redemption",
            "explanation": "Jacob Marley’s ghost (Entity 10) is the driving force behind Scrooge’s moral awakening. Marley’s spectral visitation on Christmas Eve (Entity 31) confronts Scrooge with the consequences of greed, symbolized by the chains he forged in life (Entity 10). His role extends beyond warning; he actively arranges the Three Spirits’ interventions, including the Second Spirit (Relationship 155), to guide Scrooge toward redemption. This underscores Marley’s dual role as a cautionary figure and a redemptive agent. [Data: Entities (10, 31); Relationships (11, 155)]"
        },
        {
            "summary": "Scrooge’s ownership of the Counting-House",
            "explanation": "Ebenezer Scrooge operates the Counting-House (Entity 63) following Marley’s death, maintaining their shared legacy of financial focus. The establishment symbolizes their mutual avarice, with Scrooge’s continued ownership reflecting his unresolved moral stagnation. This entity ties directly to Marley’s warning about the consequences of prioritizing profit over compassion. [Data: Entities (63); Relationships (74)]"
        },
        {
            "summary": "Christmas Eve as a pivotal temporal nexus",
            "explanation": "Christmas Eve (Entity 31) marks both the anniversary of Marley’s death and the day of his ghostly visitation to Scrooge. The date’s cold atmosphere mirrors Scrooge’s emotional isolation, while its association with Marley’s intervention and Cratchit’s brief joy highlights its thematic duality—a moment of reckoning and potential hope. [Data: Entities (31); Relationships (33)]"
        },
        {
            "summary": "Second Spirit’s role in Scrooge’s transformation",
            "explanation": "The Second Spirit (Entity 110) is dispatched by Marley to continue Scrooge’s moral education (Relationship 155). Its involvement signifies the structured progression of Scrooge’s redemption, moving from Marley’s warning to actionable guidance. This relationship underscores the community’s focus on accountability and transformation. [Data: Entities (110); Relationships (155)]"
        },
        {
            "summary": "Speculation around Marley’s Company",
            "explanation": "Marley’s Company is speculated to have inherited his wealth (Relationship 271), though details are sparse. This relationship hints at unresolved financial and legal ties from Marley’s life, potentially reflecting his enduring influence even after death. [Data: Relationships (271)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:53,126 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:53,126 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 20.0
15:52:55,875 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:52:55,887 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Scrooge's Nephew and Christmas Community",
    "summary": "The community centers around CHRISTMAS as a transformative motif, with SCROOGE'S NEPHEW serving as its primary advocate. Key entities include the MOOR, TWELFTH-NIGHT PARTY, HUT, and OLD MAN, all linked to CHRISTMAS through celebrations, gatherings, and symbolic interactions. The nephew’s persistent promotion of holiday values contrasts with Scrooge’s initial disdain, while peripheral entities illustrate the holiday’s universal reach and communal spirit.",
    "rating": 8.5,
    "rating_explanation": "The impact severity rating is high due to CHRISTMAS’s role as a catalyst for profound personal and societal transformation.",
    "findings": [
        {
            "summary": "CHRISTMAS as the central transformative motif",
            "explanation": "CHRISTMAS is the narrative and thematic core of the community, driving Scrooge’s redemption and symbolizing universal themes of generosity and human connection. Its duality—evoking both joy and isolation—mirrors Scrooge’s internal conflict. The holiday’s depiction across diverse settings (e.g., miners on the MOOR, the nephew’s party) underscores its societal reach. [Data: Entities (32), Relationships (30, 41, 221, 256, +more)]"
        },
        {
            "summary": "SCROOGE'S NEPHEW as the embodiment of Christmas spirit",
            "explanation": "SCROOGE'S NEPHEW actively champions CHRISTMAS through his annual party and unwavering advocacy for its values. His persistent invitations to Scrooge and defense of the holiday’s significance highlight his role as a foil to Scrooge’s cynicism. His actions reinforce CHRISTMAS’s redemptive potential. [Data: Entities (27), Relationships (30, 41)]"
        },
        {
            "summary": "MOOR’s role in illustrating communal joy",
            "explanation": "The MOOR, though bleak, hosts miners who celebrate CHRISTMAS with songs, emphasizing the holiday’s ability to foster joy in harsh environments. This reinforces the theme of CHRISTMAS as a unifying force across social strata. [Data: Entities (142), Relationships (221)]"
        },
        {
            "summary": "TWELFTH-NIGHT PARTY in Scrooge’s condensed timeline",
            "explanation": "The TWELFTH-NIGHT PARTY is part of Scrooge’s accelerated journey with the Ghost of Christmas Past, symbolizing the passage of time and the fleeting nature of festive opportunities. Its inclusion underscores CHRISTMAS’s broader cultural traditions. [Data: Entities (161), Relationships (256)]"
        },
        {
            "summary": "HUT and OLD MAN’s humble celebration",
            "explanation": "An unnamed OLD MAN leads carols in a HUT, demonstrating CHRISTMAS’s accessibility to even the most modest households. This contrasts with Scrooge’s wealth and isolation, highlighting the holiday’s egalitarian spirit. [Data: Entities (147, 148), Relationships (230)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:52:55,894 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:52:55,894 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 24.0
15:52:56,787 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:04,264 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:04,265 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:04,286 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "The Ghost and Tiny Tim's Transformative Community",
    "summary": "This community centers on THE GHOST, a spiritual entity guiding Ebenezer Scrooge through visions of his past, present, and future to catalyze his redemption. Key relationships include THE GHOST’s influence over Scrooge, the prophetic link between Tiny Tim’s potential death and Scrooge’s transformation, and the Cratchit family’s resilience in the face of hardship. The community’s dynamics emphasize themes of compassion, societal neglect, and the transformative power of empathy, anchored by THE GHOST’s interventions and Tiny Tim’s symbolic role.",
    "rating": 7.5,
    "rating_explanation": "The high impact severity reflects the profound moral and societal implications of Scrooge’s transformation and Tiny Tim’s survival.",
    "findings": [
        {
            "summary": "THE GHOST as the central transformative force",
            "explanation": "THE GHOST serves as the narrative and moral core of the community, compelling Scrooge to confront his past, present, and future. Its multifaceted role includes exposing Scrooge’s isolation (e.g., his broken engagement to Belle), contrasting his miserliness with Mr. Fezziwig’s generosity, and revealing grim prophecies about Tiny Tim’s death. These interventions dismantle Scrooge’s cynicism, directly leading to his redemption. [Data: Entities (90); Relationships (119, 150)]"
        },
        {
            "summary": "Tiny Tim’s pivotal role in Scrooge’s transformation",
            "explanation": "Tiny Tim’s fragility and impending death, prophesied by THE GHOST, serve as the emotional catalyst for Scrooge’s change. His survival post-redemption symbolizes the human cost of indifference and the impact of charity. Scrooge’s actions to save Tim—and his subsequent role as a 'second father'—highlight the community’s focus on interconnectedness. [Data: Entities (9); Relationships (205, 307)]"
        },
        {
            "summary": "Cratchit family’s unity amid adversity",
            "explanation": "The Cratchit family exemplifies resilience, particularly after Tiny Tim’s death. Bob Cratchit’s leadership in mourning while strengthening familial bonds underscores themes of love amid hardship. Their unity is further tied to honoring the SPIRIT OF TINY TIM, reinforcing communal solidarity. [Data: Entities (196); Relationships (307, 319)]"
        },
        {
            "summary": "The Ghost’s prophecy as a narrative device",
            "explanation": "The GHOST'S PROPHECY about Tiny Tim’s death creates urgency for Scrooge’s transformation. This vision merges personal consequence (Scrooge’s unmourned death) with societal impact (the Cratchits’ poverty), emphasizing accountability. [Data: Entities (139); Relationships (205)]"
        },
        {
            "summary": "THE GHOST’s thematic link to Christmas",
            "explanation": "THE GHOST embodies the spirit of CHRISTMAS, contrasting Scrooge’s isolation with communal joy. By revisiting Fezziwig’s festive generosity and showcasing universal kindness, it positions Christmas as a symbol of redemption. [Data: Relationships (119)]"
        },
        {
            "summary": "Spirit of Tiny Tim’s symbolic resonance",
            "explanation": "The SPIRIT OF TINY TIM, described as having a 'childish essence from God,' symbolizes innocence and enduring hope. Its connection to the Cratchit family’s unity reinforces the community’s emphasis on compassion. [Data: Entities (195); Relationships (319)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:53:04,295 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:53:04,295 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 36.0
15:53:05,291 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:05,299 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Fezziwig's Warehouse and Christmas Eve Celebration Community",
    "summary": "The community centers around Old Fezziwig, his warehouse, and the Christmas Eve celebration, which exemplify themes of generosity and human connection. Key entities include Fezziwig's Warehouse (the central location), Old Fezziwig (the benevolent employer), Dick Wilkins (Scrooge's fellow apprentice), and the Three Miss Fezziwigs (Fezziwig's daughters). Relationships highlight Old Fezziwig's management of the warehouse, employment of apprentices, and the festive event that binds these entities together.",
    "rating": 3.0,
    "rating_explanation": "The impact severity rating is low as the community primarily serves as a literary symbol of empathy and redemption with no direct real-world operational risks.",
    "findings": [
        {
            "summary": "Old Fezziwig's leadership as a model of benevolence",
            "explanation": "Old Fezziwig is depicted as a warm-hearted and generous employer who prioritized joy and community over austerity. His leadership at the warehouse, exemplified by the Christmas Eve celebration, directly contrasts with Scrooge’s later miserliness and underscores the novel’s themes of redemption. [Data: Entities (93), Relationships (124, 128)]"
        },
        {
            "summary": "Fezziwig's Warehouse as the community's central hub",
            "explanation": "Fezziwig's Warehouse serves as the physical and symbolic heart of the community, where apprentices like Scrooge and Dick Wilkins worked. Its association with Old Fezziwig’s values and the festive celebration reinforces its role as a space for human connection. [Data: Entities (94), Relationships (116, 124)]"
        },
        {
            "summary": "Dick Wilkins' role as Scrooge's peer",
            "explanation": "Dick Wilkins, Scrooge’s fellow apprentice at the warehouse, highlights the collaborative and equitable environment fostered by Old Fezziwig. Their shared experience underscores the contrast between Fezziwig’s mentorship and Scrooge’s later isolation. [Data: Entities (99), Relationships (128)]"
        },
        {
            "summary": "Three Miss Fezziwigs' participation in festivities",
            "explanation": "The Three Miss Fezziwigs attended the Christmas Eve celebration, embodying the familial and inclusive spirit of the event. Their presence emphasizes the integration of family and community in Old Fezziwig’s ethos. [Data: Entities (100), Relationships (135)]"
        },
        {
            "summary": "Christmas Eve celebration as a transformative event",
            "explanation": "The Christmas Eve celebration at Fezziwig’s Warehouse is a pivotal event that symbolizes joy and human connection. Scrooge’s nostalgic recollection of it during the Ghost’s vision highlights its lasting emotional impact and role in his eventual redemption. [Data: Entities (93), Relationships (135)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:53:05,308 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:53:05,309 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 37.0
15:53:07,705 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:08,361 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:10,201 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:11,737 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:11,750 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Marley's Ghost Visit and Alhamia Prison Symbolism",
    "summary": "The community centers on the symbolic and narrative connections between Marley's Ghost Visit, a transformative supernatural event, and Alhamia Prison, which serves dual roles as a literary metaphor for moral consequences and an inferred detention facility in the fictional nation of Tiruzia. The entities are linked through metaphorical imprisonment themes, reflecting moral allegory and speculative geopolitical contexts.",
    "rating": 4.0,
    "rating_explanation": "The impact severity is low due to the community's primarily symbolic and literary nature, with limited direct real-world implications.",
    "findings": [
        {
            "summary": "Marley's Ghost Visit as a catalyst for transformation",
            "explanation": "Marley's Ghost Visit (Entity 61) is a pivotal event in which Jacob Marley’s spectre confronts Ebenezer Scrooge, initiating his moral awakening. The haunting, marked by chains symbolizing spiritual imprisonment, serves as a narrative device to critique societal indifference. This event’s metaphorical weight ties it to broader themes of accountability and redemption. [Data: Entities (61); Relationships (73)]"
        },
        {
            "summary": "Alhamia Prison’s dual symbolic and inferred roles",
            "explanation": "Alhamia Prison (Entity 62) functions both as a literary metaphor for the consequences of moral neglect (linked to Scrooge’s past) and as an inferred detention site in Tiruzia’s geopolitical context. While its explicit connection to Tiruzia was flagged as erroneous, contextual clues suggest its speculative role in narratives involving detainee Samuel Namara. This duality underscores its thematic versatility. [Data: Entities (62)]"
        },
        {
            "summary": "Metaphorical linkage of imprisonment themes",
            "explanation": "The relationship between Marley's Ghost Visit and Alhamia Prison (Relationship 73) hinges on shared symbolism of confinement. Marley’s chains metaphorically evoke purgatorial torment, paralleling Alhamia Prison’s representation of moral and physical imprisonment. This connection reinforces the community’s focus on consequences of ethical failure. [Data: Relationships (73); Entities (61, 62)]"
        },
        {
            "summary": "Tiruzia’s contextual association with Alhamia Prison",
            "explanation": "Though Alhamia Prison’s explicit link to Tiruzia was deemed erroneous, circumstantial inferences position it as a speculative detention facility in Tiruzia’s narratives. This inferred role, while not directly substantiated, highlights the prison’s adaptability as a narrative device across allegorical and geopolitical frameworks. [Data: Entities (62)]"
        },
        {
            "summary": "Cultural and moral allegory in community dynamics",
            "explanation": "The community’s entities collectively emphasize moral accountability through supernatural and carceral imagery. Marley’s Ghost Visit critiques indifference, while Alhamia Prison symbolizes its repercussions. These themes resonate in both literary and speculative contexts, underscoring the community’s role as a vehicle for ethical discourse. [Data: Entities (61, 62); Relationships (73)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:53:11,764 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:53:11,764 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 16.0
15:53:13,370 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:17,988 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:17,999 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Fezziwig, Mrs. Fezziwig, and the Domestic Ball Community",
    "summary": "The community centers on Fezziwig and Mrs. Fezziwig, who collaboratively hosted the festive Domestic Ball. Their roles as generous employers and hospitable hosts are intertwined with apprentices like Dick and the Ghost of Christmas Past, which revealed the event’s memory to Scrooge. The community symbolizes generosity, joy, and communal spirit, with relationships emphasizing collaboration and shared celebrations.",
    "rating": 2.0,
    "rating_explanation": "The impact severity rating is low due to the community’s symbolic and fictional nature, focusing on positive themes without real-world operational risks.",
    "findings": [
        {
            "summary": "Fezziwig’s role as a generous employer and event host",
            "explanation": "Fezziwig is depicted as a warm, generous employer who organized the Domestic Ball, fostering camaraderie among apprentices like Scrooge and Dick. His leadership contrasts with Scrooge’s later miserliness, symbolizing the transformative power of kindness. The ball exemplified his commitment to employee well-being and festive inclusivity. [Data: Entities (21), Relationships (139, 24)]"
        },
        {
            "summary": "Mrs. Fezziwig’s collaborative partnership with Fezziwig",
            "explanation": "Mrs. Fezziwig is Fezziwig’s spouse and co-host, actively participating in the Domestic Ball through spirited dancing and event coordination. Their partnership underscores shared joy and hospitality, reinforcing the communal atmosphere. Her role is consistently tied to Fezziwig, with no contradictions in their collaborative dynamic. [Data: Entities (22), Relationships (24, 134)]"
        },
        {
            "summary": "Domestic Ball as the community’s central event",
            "explanation": "The Domestic Ball, hosted by Fezziwig, is the pivotal event uniting apprentices and spirits. It ended at 11 PM and was later revealed to Scrooge by the Ghost of Christmas Past, highlighting its narrative significance. The ball embodies themes of generosity and serves as a counterpoint to Scrooge’s isolation. [Data: Entities (106), Relationships (139, 147, 146)]"
        },
        {
            "summary": "Dick’s participation as an apprentice",
            "explanation": "Dick, Scrooge’s fellow apprentice under Fezziwig, participated in the Domestic Ball. His involvement reflects Fezziwig’s inclusive leadership and the apprentices’ integration into the celebratory community. [Data: Entities (105), Relationships (147)]"
        },
        {
            "summary": "Ghost of Christmas Past’s revelatory role",
            "explanation": "The Ghost of Christmas Past showed Scrooge the memory of the Domestic Ball, emphasizing its emotional and moral significance. This act underscores the event’s lasting impact on Scrooge’s transformation. [Data: Entities (104), Relationships (146)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:53:18,4 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:53:18,4 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 39.0
15:53:20,137 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:27,5 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:30,578 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:37,35 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:40,798 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:42,667 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:45,846 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:49,342 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:50,975 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:53,527 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:53:53,537 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "PHANTOM and the Impact of the Deceased Man's Death",
    "summary": "The community centers on PHANTOM (the Ghost of Christmas Yet to Come), a spectral entity that reveals consequential futures, and the ripple effects of a deceased man's death on Caroline and her husband. PHANTOM’s role in guiding Ebenezer Scrooge intersects with the financial relief experienced by Caroline’s family due to the creditor’s death. Key relationships highlight PHANTOM’s influence on moral reckoning and the interconnectedness of the deceased man’s death with Caroline’s family dynamics.",
    "rating": 3.5,
    "rating_explanation": "The impact severity is low-to-moderate as the community is a literary allegory with moral implications but no direct real-world threat.",
    "findings": [
        {
            "summary": "PHANTOM as a catalyst for existential reckoning",
            "explanation": "PHANTOM, the Ghost of Christmas Yet to Come, serves as the central entity driving moral transformation by revealing bleak futures. Its spectral presence and silent guidance force Ebenezer Scrooge to confront the consequences of his greed, including societal indifference toward his death and the suffering of others like the Cratchit family. This entity’s allegorical role underscores themes of mortality and accountability. [Data: Entities (179), Relationships (278)]"
        },
        {
            "summary": "Financial relief from the deceased man’s death",
            "explanation": "The death of the unnamed creditor (referred to as 'MAN'S DEATH' and 'DECEASED MAN') directly impacts Caroline and her husband, sparing them from debt. Caroline’s husband had previously attempted to negotiate with the creditor, highlighting the family’s precarious financial state. The creditor’s death brings conflicted relief, emphasizing the moral ambiguity of benefiting from another’s demise. [Data: Entities (189, 191), Relationships (301, 303, 304)]"
        },
        {
            "summary": "Caroline’s family dynamics and ethical conflict",
            "explanation": "Caroline and her husband experience both relief and guilt over the creditor’s death. Their reaction reflects the tension between survival and morality, as the death resolves their financial strain but raises ethical questions. This dynamic mirrors PHANTOM’s broader theme of consequential human choices. [Data: Entities (188, 190), Relationships (301, 304)]"
        },
        {
            "summary": "The deceased man’s role as a narrative pivot",
            "explanation": "Though unnamed, the deceased creditor’s death is pivotal, triggering Caroline’s relief and symbolizing the interconnectedness of individual actions. His role as a creditor ties financial systems to personal morality, a motif reinforced by PHANTOM’s visions of Scrooge’s similarly transactional legacy. [Data: Entities (189, 191), Relationships (303, 304)]"
        },
        {
            "summary": "PHANTOM’s indirect influence on peripheral characters",
            "explanation": "While PHANTOM primarily interacts with Scrooge, its revelations indirectly contextualize the plight of Caroline’s family. The spirit’s emphasis on societal consequences extends to secondary characters, illustrating how individual choices ripple through communities. [Data: Entities (179), Relationships (278)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:53:53,543 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:53:53,543 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 40.0
15:54:03,861 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:04,577 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:10,646 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:10,656 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "United States and First of Exchange Financial Framework",
    "summary": "The community centers on the United States as the regulatory and jurisdictional anchor for entities like Project Gutenberg and the financial document 'First of Exchange.' The United States governs copyright compliance, charity operations, and financial securities frameworks, while the First of Exchange references financial securities tied to U.S. regulations. Their relationship highlights the intersection of legal and financial governance within the community.",
    "rating": 4.5,
    "rating_explanation": "The impact severity rating is moderate due to the community's foundational role in legal and financial compliance frameworks, which are critical but not immediately disruptive.",
    "findings": [
        {
            "summary": "United States as regulatory and jurisdictional anchor",
            "explanation": "The United States serves as the primary jurisdiction for Project Gutenberg, ensuring compliance with U.S. copyright laws, charity regulations, and financial governance. Its legal framework enables the distribution of public domain works and tax-deductible donations, anchoring the community's operations. [Data: Entities (72)]"
        },
        {
            "summary": "First of Exchange's financial ties to U.S. securities",
            "explanation": "The 'First of Exchange' document is directly tied to U.S. financial securities, indicating compliance with transactional or regulatory requirements. This connection underscores the role of U.S. financial frameworks in governing community entities. [Data: Entities (71), Relationships (89)]"
        },
        {
            "summary": "Legal compliance underpinning Project Gutenberg",
            "explanation": "Project Gutenberg operates under U.S. copyright laws, ensuring most distributed works are in the public domain. Compliance with federal and state charity regulations further solidifies its nonprofit status, reflecting adherence to legal standards. [Data: Entities (72)]"
        },
        {
            "summary": "Intersection of financial and legal governance",
            "explanation": "The relationship between the First of Exchange and the United States highlights how financial documents are embedded within broader legal frameworks. This interplay ensures transactional compliance while aligning with national regulations. [Data: Relationships (89)]"
        },
        {
            "summary": "Public domain accessibility as a community pillar",
            "explanation": "The U.S. public domain status of materials distributed by Project Gutenberg is a cornerstone of the community, enabling free access to cultural works. This aligns with the Foundation's mission and legal permissions. [Data: Entities (72)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:54:10,663 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:54:10,663 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 44.0
15:54:23,742 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:23,752 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Old Joe's Pawnshop Network and Stolen Goods Trade",
    "summary": "The community centers around Old Joe, an elderly pawnbroker operating a dilapidated shop that serves as a hub for illicit transactions. Key entities include Old Joe's Shop, the Man in Faded Black, and a Woman, all linked through the sale of stolen goods. The community thrives on exploiting criminal activity and moral ambiguity, with Old Joe acting as the primary facilitator of these exchanges.",
    "rating": 7.5,
    "rating_explanation": "The high impact severity reflects systemic exploitation of vulnerable individuals, active trade in stolen goods, and potential legal risks to the community.",
    "findings": [
        {
            "summary": "Old Joe's central role in illicit trade",
            "explanation": "Old Joe is the linchpin of this community, operating a shop explicitly described as a hub for purchasing stolen goods. His willingness to engage in morally ambiguous transactions, including buying items from a deceased man’s estate, underscores his role in sustaining criminal activity. The shop’s squalor and Old Joe’s reputation for capitalizing on desperation highlight the systemic exploitation at play. [Data: Entities (180), Relationships (279, 282, 291, 292, +more)]"
        },
        {
            "summary": "Old Joe's Shop as a criminal nexus",
            "explanation": "Old Joe's Shop is structurally critical to the community, serving as both a physical and operational base for illegal transactions. The shop’s cluttered, neglected condition reflects its role in masking illicit activities while facilitating covert exchanges. Ownership ties directly to Old Joe, emphasizing its centrality to the network. [Data: Entities (184), Relationships (282)]"
        },
        {
            "summary": "Man in Faded Black's involvement in stolen goods",
            "explanation": "The Man in Faded Black is a direct participant in the illicit trade, selling stolen personal items like seals and a brooch to Old Joe. This transaction exemplifies the community’s reliance on petty theft and the resale of stolen belongings. His relationship with Old Joe highlights the shop’s role as a consistent outlet for criminal activity. [Data: Entities (185), Relationships (292)]"
        },
        {
            "summary": "Woman's contribution to criminal transactions",
            "explanation": "The Woman sold stolen bed-curtains and blankets from Scrooge’s deathbed to Old Joe, demonstrating her active role in exploiting vulnerable situations. Her participation in the Sale of Stolen Goods event underscores the community’s callous disregard for ethical boundaries. [Data: Entities (187), Relationships (291, 298)]"
        },
        {
            "summary": "Sale of Stolen Goods as a systemic event",
            "explanation": "The Sale of Stolen Goods is a recurring event that epitomizes the community’s exploitation of death and desperation. The transaction involving Scrooge’s belongings reveals a pattern of morally bankrupt behavior, with Old Joe enabling and profiting from these exchanges. [Data: Entities (186), Relationships (298)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:54:23,758 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:54:23,759 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 41.0
15:54:24,495 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:24,511 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Project Gutenberg and Michael S. Hart's Digital Literary Initiative",
    "summary": "The community centers on Project Gutenberg, a pioneering digital library founded by Michael S. Hart in 1971 and sustained by the nonprofit Project Gutenberg Literary Archive Foundation established in 2001. Key entities include the U.S. (governing its copyright compliance), the Online Distributed Proofreading Team (volunteer-driven digitization), and Hart himself. Relationships highlight the platform’s operational framework, legal adherence, and global distribution of over 60,000 free eBooks, including works like *A Christmas Carol*. The community’s structure reflects a mission-driven, volunteer-supported model prioritizing open access to public domain cultural works.",
    "rating": 6.5,
    "rating_explanation": "The impact severity rating reflects Project Gutenberg’s significant cultural and educational contributions, tempered by copyright limitations and reliance on volunteer efforts.",
    "findings": [
        {
            "summary": "Project Gutenberg as the central entity",
            "explanation": "Project Gutenberg is the core entity, with a high degree of connectivity (degree 7) to other community members. It directly links to its founder Michael S. Hart, the U.S. (governing copyright compliance), and the Online Distributed Proofreading Team. Its role in digitizing and distributing over 60,000 eBooks, including *A Christmas Carol*, underscores its cultural preservation mandate. [Data: Entities (0), Relationships (0, 357, 1, 364)]"
        },
        {
            "summary": "Michael S. Hart’s foundational leadership",
            "explanation": "Michael S. Hart originated Project Gutenberg in 1971 and led its eBook production for 40 years. His vision established the platform’s grassroots ethos and open-access principles. His sustained involvement (relationship degree 8) highlights his enduring influence on the project’s mission and operational model. [Data: Entities (216), Relationships (364)]"
        },
        {
            "summary": "Nonprofit foundation ensures sustainability",
            "explanation": "The Project Gutenberg Literary Archive Foundation, established in 2001 (entity 219), was created to secure the project’s long-term viability. This relationship (degree 11) mitigates risks associated with volunteer dependency and funding, ensuring continuity in digitizing public domain works. [Data: Entities (219), Relationships (361)]"
        },
        {
            "summary": "U.S. copyright law governs operations",
            "explanation": "Project Gutenberg operates under U.S. copyright law (relationship degree 9), limiting its distribution to works in the U.S. public domain. This legal framework reduces liability risks but constrains global content diversity. Compliance is explicitly noted in disclaimers. [Data: Entities (214), Relationships (357)]"
        },
        {
            "summary": "Volunteer-driven proofreading model",
            "explanation": "The Online Distributed Proofreading Team (entity 14) collaborates with Project Gutenberg (relationship degree 8) to digitize and proofread eBooks. This volunteer network enables cost-effective operations but introduces scalability challenges and reliance on unpaid labor. [Data: Entities (14), Relationships (1)]"
        },
        {
            "summary": "Global access with U.S.-centric limitations",
            "explanation": "While Project Gutenberg serves a global audience, its content is dictated by U.S. public domain status, excluding works under foreign copyrights. This limits its international relevance but ensures legal compliance. [Data: Entities (0, 214)]"
        },
        {
            "summary": "Legacy of open access and digital preservation",
            "explanation": "Project Gutenberg’s legacy lies in its early adoption of open-access principles and device-agnostic formats (e.g., EPUB, HTML). Its avoidance of DRM and emphasis on preservation cement its role in digital literacy. [Data: Entities (0)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:54:24,517 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:54:24,518 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 43.0
15:54:25,809 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:30,485 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:30,487 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Project Gutenberg Literary Archive Foundation and U.S. Compliance Network",
    "summary": "The community centers on the Project Gutenberg Literary Archive Foundation (PGLAF), a nonprofit managing the digitization and distribution of public-domain works. PGLAF operates under U.S. federal and state legal frameworks, with key relationships to Utah (operational base), Mississippi (incorporation), the IRS (tax-exempt status), and Salt Lake City (physical office). Its activities rely on compliance with copyright law, tax regulations, and trademark management to sustain its mission of free literary access.",
    "rating": 4.5,
    "rating_explanation": "The impact severity rating is moderate, reflecting PGLAF’s positive educational mission balanced by legal and operational dependencies that pose minimal but non-zero risks.",
    "findings": [
        {
            "summary": "Central role of PGLAF in the community",
            "explanation": "PGLAF is the core entity, managing Project Gutenberg’s digitization efforts, trademark, and donor funds. Its compilation copyright and tax-exempt status enable legal distribution of public-domain works while ensuring compliance with U.S. nonprofit regulations. The foundation’s decentralized structure—incorporated in Mississippi but operating in Utah—highlights its hybrid legal and operational footprint. [Data: Entities (213), Relationships (353, 362, 358)]"
        },
        {
            "summary": "Tax-exempt status critical for donor compliance",
            "explanation": "The IRS-granted tax-exempt status (EIN 64-6221541) allows PGLAF to solicit tax-deductible donations, a cornerstone of its funding model. This status requires adherence to federal charity laws, including transparent financial reporting and restrictions on political activities. The relationship between PGLAF and the IRS underscores regulatory oversight inherent to its nonprofit operations. [Data: Entities (215, 220), Relationships (363, 366)]"
        },
        {
            "summary": "Legal incorporation in Mississippi vs. Utah operations",
            "explanation": "PGLAF is incorporated in Mississippi but operates physically in Utah (809 North 1500 West, Salt Lake City). This structure separates its legal identity from its operational base, potentially optimizing tax and regulatory conditions. Mississippi’s corporate laws govern PGLAF’s nonprofit standing, while Utah hosts its day-to-day financial and administrative activities. [Data: Entities (217, 221), Relationships (358, 362)]"
        },
        {
            "summary": "Compliance with U.S. copyright and charity laws",
            "explanation": "PGLAF’s operations are tightly bound to U.S. legal frameworks, particularly copyright law and federal charity regulations. Its focus on U.S. public-domain works ensures compliance but limits international distribution where copyright terms differ. The foundation’s adherence to these laws mitigates legal risks while constraining its global reach. [Data: Relationships (353)]"
        },
        {
            "summary": "Trademark and compilation copyright management",
            "explanation": "PGLAF holds the Project Gutenberg™ trademark and compilation copyright, allowing it to enforce distribution terms and protect brand integrity. This legal control prevents commercial misuse of its digital library while permitting third-party partnerships under strict guidelines. These rights are central to maintaining the project’s open-access ethos. [Data: Entities (213)]"
        },
        {
            "summary": "Salt Lake City as operational hub",
            "explanation": "Salt Lake City hosts PGLAF’s business office, linking it to Utah’s regulatory environment. The city’s role as an operational base supports donor management, financial oversight, and technological infrastructure, though the foundation’s digital-first model minimizes physical footprint. [Data: Entities (218), Relationships (367)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:54:30,492 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:54:30,492 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 45.0
15:54:33,266 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:35,706 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:45,229 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:54:45,240 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Scrooge’s Counting-House and Clerk Exploitation Network",
    "summary": "The community centers on Scrooge’s Counting-House, a business office characterized by harsh working conditions and exploitative labor practices. The Clerk, a key entity, endures systemic neglect under Scrooge’s employment, while Scrooge’s conflict with his Nephew highlights interpersonal tensions. The Counting-House’s location in the foggy City underscores its role as a microcosm of Victorian-era labor exploitation. Relationships between these entities emphasize themes of cruelty, resilience, and social critique.",
    "rating": 6.5,
    "rating_explanation": "The impact severity rating reflects the community’s systemic labor exploitation and its broader societal implications, though mitigated by its fictional literary context.",
    "findings": [
        {
            "summary": "Scrooge’s Counting-House as a center of exploitation",
            "explanation": "Scrooge’s Counting-House is the operational hub for financial activities managed under oppressive conditions. The office is described as frigid and minimally heated, symbolizing Scrooge’s miserly cruelty. The Clerk works here under constant anxiety about job security, reflecting systemic labor exploitation. This entity’s centrality to the community underscores its role in perpetuating economic and social inequities. [Data: Entities (29), Relationships (31, 32)]"
        },
        {
            "summary": "Clerk’s role as a symbol of exploited labor",
            "explanation": "The Clerk is a critical entity embodying the plight of underpaid Victorian workers. Despite enduring harsh conditions—including a dim, oppressive workspace and insufficient heating—he demonstrates resilience and kindness, such as exchanging heartfelt Christmas greetings with Scrooge’s Nephew. His duality as both victim and moral contrast to Scrooge highlights the narrative’s critique of labor practices. [Data: Entities (28), Relationships (31)]"
        },
        {
            "summary": "Scrooge’s interpersonal conflict with Nephew",
            "explanation": "Scrooge’s bitter argument with his Nephew over Christmas values reveals his rejection of familial warmth and social connection. This relationship underscores Scrooge’s moral rigidity and isolation, which indirectly perpetuates the Clerk’s suffering by prioritizing profit over humane working conditions. [Data: Relationships (38)]"
        },
        {
            "summary": "Counting-House’s location in the City",
            "explanation": "The Counting-House’s placement in a foggy, urban area (the City) contextualizes its role within broader societal structures. This setting reinforces themes of industrialization’s dehumanizing effects and the anonymity of systemic exploitation. [Data: Relationships (32)]"
        },
        {
            "summary": "Duality of Clerk’s character as critique",
            "explanation": "The Clerk’s portrayal as both oppressed and resilient serves as a narrative device to critique Victorian labor norms. His quiet dignity amid adversity contrasts with Scrooge’s cruelty, emphasizing the story’s call for empathy and systemic reform. [Data: Entities (28)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:54:45,246 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:54:45,246 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 49.0
15:55:05,576 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:55:05,584 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Scrooge and the Yes and No Game Community",
    "summary": "The community centers on the 'Yes and No Game,' a guessing game hosted by Fred where participants deduce Scrooge as the answer. The game’s riddle references London, Market, and Menagerie as key locations, establishing their roles in the puzzle. Scrooge is the focal subject of the game, while London, Market, and Menagerie serve as contextual elements in the riddle’s narrative.",
    "rating": 2.0,
    "rating_explanation": "The impact severity rating is low due to the recreational and fictional nature of the game, posing minimal real-world consequences.",
    "findings": [
        {
            "summary": "Central role of the Yes and No Game",
            "explanation": "The Yes and No Game is the core entity in this community, functioning as a recreational activity where participants guess Scrooge as the answer. Its high degree (5) and multiple relationships with other entities highlight its structural importance. The game’s design as a riddle involving London, Market, and Menagerie underscores its narrative complexity. [Data: Entities (168), Relationships (247, 255, 257, 258)]"
        },
        {
            "summary": "Scrooge as the game’s subject",
            "explanation": "Scrooge is the central figure in the Yes and No Game, with participants tasked with identifying him. The relationship between Scrooge and the game (ID 247) is the strongest in the dataset (combined_degree 80), emphasizing his pivotal role. This connection suggests Scrooge’s significance in the game’s thematic framework. [Data: Relationships (247)]"
        },
        {
            "summary": "London’s contextual relevance in the riddle",
            "explanation": "London is referenced in the game’s riddle as the habitat of an imagined animal. Its relationship with the Yes and No Game (ID 255) positions it as a critical geographic clue. However, London’s low degree (2) indicates limited direct influence beyond the riddle’s narrative. [Data: Entities (160), Relationships (255)]"
        },
        {
            "summary": "Market and Menagerie as excluded locations",
            "explanation": "The Market and Menagerie are explicitly excluded in the riddle, clarifying that the animal was neither slaughtered in the Market nor kept in the Menagerie. These entities serve to narrow down participants’ deductions, highlighting their role as red herrings. Their low degrees (1 each) reflect their peripheral importance. [Data: Entities (162, 163), Relationships (257, 258)]"
        },
        {
            "summary": "Structural simplicity of the community",
            "explanation": "The community’s structure is linear, with the Yes and No Game acting as a hub connected to Scrooge, London, Market, and Menagerie. The absence of complex inter-entity relationships beyond the game suggests a straightforward, event-driven network. This simplicity limits the community’s potential for broader impact. [Data: Entities (168, 160, 162, 163), Relationships (247, 255, 257, 258)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:55:05,591 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:55:05,591 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 53.0
15:55:19,640 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:55:19,651 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Ebenezer Scrooge and the Redemption Network",
    "summary": "The community centers on Ebenezer Scrooge, a miserly businessman whose relationships span institutional entities (e.g., Union Workhouses, Poor Law), familial ties (e.g., Tim, his clerk’s son), and spectral influences (e.g., Jacob Marley’s ghost). Scrooge’s interactions with these entities drive his moral transformation from a cold-hearted figure to a benevolent benefactor, impacting both personal and societal dynamics. Key relationships highlight his advocacy for punitive poverty systems, disdain for social traditions, and eventual redemption through empathy.",
    "rating": 6.5,
    "rating_explanation": "The moderate-high severity reflects Scrooge’s dual impact: perpetuating systemic indifference to poverty while later catalyzing localized positive change through personal redemption.",
    "findings": [
        {
            "summary": "Scrooge’s institutional influence on poverty systems",
            "explanation": "Scrooge actively endorses punitive institutions like Union Workhouses, the Treadmill, and the Poor Law, which prioritize incarceration and labor over charity [Data: Entities (40, 41, 42, 49); Relationships (44, 45, 46, 50)]. His support for these systems underscores his initial indifference to societal welfare, aligning with industrial-era critiques of institutionalized cruelty. These policies directly affect vulnerable populations, as implied by his clerk Bob Cratchit’s underpaid status and the fragility of Tiny Tim’s health [Data: Entities (23); Relationships (20)]."
        },
        {
            "summary": "Marley’s spectral intervention as a catalyst for change",
            "explanation": "Jacob Marley’s ghost serves as the pivotal force in Scrooge’s transformation, warning him of eternal suffering unless he reforms [Data: Relationships (15)]. Marley’s chains, symbolizing lifelong greed, and his desperate plea to Scrooge highlight the consequences of moral neglect. This relationship underscores the thematic link between accountability and redemption, framing Scrooge’s journey as a cautionary tale [Data: Entities (16); Relationships (15, 156)]."
        },
        {
            "summary": "Scrooge’s contempt for social traditions",
            "explanation": "Scrooge dismisses Christmas, Happy New Year greetings, and charitable acts, epitomizing his isolation [Data: Entities (36, 48); Relationships (35, 36, 37, 47)]. His sarcastic suggestion that his nephew join Parliament and threats to retire to Bedlam (a historic mental hospital) reveal his disdain for social norms and familial bonds [Data: Entities (34, 35); Relationships (35, 36)]. These interactions reinforce his reputation as a misanthrope prior to his redemption."
        },
        {
            "summary": "Redemption through empathy for the Cratchit family",
            "explanation": "Scrooge’s transformation is catalyzed by witnessing the Cratchit family’s hardships, particularly Tiny Tim’s fragile health [Data: Entities (23); Relationships (20, 154)]. The Ghost of Christmas Present exposes Scrooge to their struggles, igniting his first flicker of empathy. Post-redemption, Scrooge raises Bob’s salary and ensures Tim’s survival, demonstrating his shift from indifference to compassion [Data: Entities (16); Relationships (154)]."
        },
        {
            "summary": "Architectural and historical symbolism",
            "explanation": "Scrooge’s office and the Dutch Merchant’s fireplace symbolize his isolation and entrenchment in the past [Data: Entities (60, 156); Relationships (68, 236)]. The church tower’s bell and Whitechapel needles metaphorically critique his sharp, unyielding nature [Data: Entities (47, 155); Relationships (48, 248)]. These elements frame his environment as an extension of his moral rigidity."
        },
        {
            "summary": "Physical and spiritual resistance to change",
            "explanation": "Scrooge’s struggle to extinguish the Ghost of Christmas Past’s light illustrates his initial resistance to self-reflection [Data: Entities (112); Relationships (153)]. This physical confrontation mirrors his internal conflict, emphasizing the difficulty of breaking lifelong habits. The spirits’ relentless exposure to his past, present, and future ultimately shatters his indifference [Data: Entities (16, 111); Relationships (153, 154)]."
        },
        {
            "summary": "Legacy of Fezziwig’s mentorship",
            "explanation": "The Ghost of Christmas Past revisits Scrooge’s apprenticeship under Fezziwig, a jovial employer whose kindness contrasts with Scrooge’s later miserliness [Data: Entities (16)]. This comparison critiques Scrooge’s abandonment of humane values in pursuit of wealth, highlighting Fezziwig’s role as a moral benchmark lost to greed."
        },
        {
            "summary": "Media and cultural references",
            "explanation": "Scrooge’s reference to Joe Miller, a historical comedian, during his redemption humorously contrasts his earlier severity [Data: Entities (208); Relationships (336)]. The Christmas Carol Incident, where a singer flees Scrooge’s hostility, underscores his reputation as a societal outlier [Data: Entities (48); Relationships (47)]."
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:55:19,657 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:55:19,658 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 46.0
15:55:56,593 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:55:57,465 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:00,376 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:04,284 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:05,849 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:08,585 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:11,495 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:12,713 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:13,176 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:15,335 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:23,140 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:31,625 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:32,870 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:33,363 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:53,839 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:56:59,428 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:03,676 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:09,641 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:14,897 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:15,719 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:16,760 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:17,430 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:22,994 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:55,796 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:56,916 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:59,152 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:57:59,157 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "The Ghost of Christmas Present and Associated Institutions",
    "summary": "The community centers on the Ghost of Christmas Present, who guides Scrooge through transformative visions tied to institutions like the Almshouse, Hospital, and Gaol. The Ghost’s role is temporally bound to Midnight, marking the conclusion of its influence. These entities are interconnected through the Ghost’s visits, which aim to impart moral lessons on charity, hope, and redemption.",
    "rating": 4.0,
    "rating_explanation": "The impact severity is moderate, reflecting the Ghost’s profound but allegorical influence on Scrooge’s transformation, with limited real-world implications.",
    "findings": [
        {
            "summary": "Central Role of the Ghost of Christmas Present",
            "explanation": "The Ghost of Christmas Present is the core entity in this community, directly linked to all other institutions and Midnight. It serves as Scrooge’s guide, revealing consequential visions at the Almshouse, Hospital, and Gaol to foster empathy and moral growth. The Ghost’s high degree (5) underscores its narrative significance. [Data: Entities (159); Relationships (251, 252, 253, 254)]"
        },
        {
            "summary": "Midnight as a Temporal Boundary",
            "explanation": "Midnight marks the endpoint of the Ghost’s existence and influence, symbolizing the urgency of Scrooge’s transformation. This temporal constraint heightens the stakes of the Ghost’s lessons. The relationship between the Ghost and Midnight (degree 6) emphasizes its pivotal role. [Data: Entities (169); Relationships (251)]"
        },
        {
            "summary": "Almshouse’s Lesson on Poverty and Resilience",
            "explanation": "The Ghost visits the Almshouse to expose Scrooge to scenes of poverty, challenging his indifference to societal suffering. This institution underscores themes of charity and resilience, directly tied to the Ghost’s mission. [Data: Entities (165); Relationships (252)]"
        },
        {
            "summary": "Hospital’s Contrast of Illness and Hope",
            "explanation": "At the Hospital, the Ghost contrasts physical sickness with emotional cheer, illustrating hope amid adversity. This visit reinforces the community’s focus on empathy and human connection. [Data: Entities (166); Relationships (253)]"
        },
        {
            "summary": "Gaol’s Exploration of Redemption and Misery",
            "explanation": "The Gaol visit highlights the plight of prisoners, emphasizing redemption and the consequences of moral failure. This institution deepens the Ghost’s lessons on societal responsibility. [Data: Entities (167); Relationships (254)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:57:59,164 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:57:59,164 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 1.0
15:58:00,507 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:04,968 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:05,192 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:05,600 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:08,416 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:11,58 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:38,67 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:38,73 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Ghost of Christmas Past and Scrooge's Reclamation Journey",
    "summary": "The community centers on Ebenezer Scrooge's moral redemption guided by the Ghost of Christmas Past, with ancillary geographical entities like the Open Country Road and Fields serving as symbolic settings. The Ghost's role as a spiritual mentor directly connects to Scrooge's transformative journey, while the rural locations provide contextual backdrops for his introspective visions.",
    "rating": 6.5,
    "rating_explanation": "The impact severity is moderate, reflecting Scrooge's personal transformation's significance but limited immediate external societal consequences.",
    "findings": [
        {
            "summary": "Ghost of Christmas Past as primary catalyst",
            "explanation": "The Ghost of Christmas Past (Entity 11) is the central force driving Scrooge's transformation through targeted memory recall. Its detailed description emphasizes its role as both compassionate guide and truth-revealer, using formative moments like Scrooge's relationship with Fan and Fezziwig to dismantle his emotional defenses. The Spirit's interventions are explicitly designed to prevent spiritual ruin by reconnecting Scrooge to suppressed humanity [Data: Entities (11); Relationships (12)]."
        },
        {
            "summary": "Scrooge's Reclamation as core narrative",
            "explanation": "Scrooge's Reclamation (Entity 75) is framed as an intensive psychological process tied to confronting past behaviors. Relationship 92 positions Scrooge as the subject of this journey, with the Ghost's guidance creating a mentor-protégé dynamic critical to the redemption arc. The process' success carries implications for Scrooge's future relationships and societal role [Data: Entities (75); Relationships (92)]."
        },
        {
            "summary": "Geographical symbolism in transformation",
            "explanation": "The Open Country Road (Entity 77) and Fields (Entity 80) form a symbolic landscape through Relationship 98. These locations likely represent Scrooge's emotional 'openness' during his journey, with rural imagery contrasting his urban miser persona. Their minimal descriptions suggest environmental symbolism rather than active narrative components [Data: Entities (77,80); Relationships (98)]."
        },
        {
            "summary": "Sensory triggers in memory recall",
            "explanation": "The Ghost employs music and festive sensory cues (detailed in Entity 11's description) to bypass Scrooge's intellectual defenses. This methodology demonstrates strategic use of emotional triggers, making memories visceral rather than purely cognitive. Such techniques heighten the intervention's psychological impact on Scrooge [Data: Entities (11)]."
        },
        {
            "summary": "Thematic focus on lost connections",
            "explanation": "Entity 11's description emphasizes Scrooge's severed bonds with Fan and Fred as central to his moral decline. The Ghost systematically revisits these relationships, framing communal ties as antidotes to isolation. This thematic thread underpins the entire reclamation process [Data: Entities (11); Relationships (12)]."
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:58:38,81 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:58:38,81 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 8.0
15:58:47,920 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:47,941 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Ebenezer Scrooge and the Ghost of Christmas Yet to Come",
    "summary": "The community centers on Ebenezer Scrooge, whose moral transformation is catalyzed by supernatural entities, including the Ghost of Christmas Yet to Come. Key relationships involve Scrooge’s interactions with the Ghost, The City as a symbolic backdrop, and supporting entities like Jacob Marley’s ghost, Bob Cratchit, and allegorical figures representing societal ills. The Ghost’s visions of Scrooge’s neglected grave and the City’s indifferent future drive his redemption, impacting his business practices and personal relationships.",
    "rating": 7.5,
    "rating_explanation": "The impact severity is high due to Scrooge’s profound societal influence post-redemption, altering economic and moral dynamics within the City.",
    "findings": [
        {
            "summary": "Scrooge’s redemption as the community’s transformative core",
            "explanation": "Ebenezer Scrooge’s awakening to compassion reshapes his relationships with employees like Bob Cratchit, evidenced by his salary raise announcement [Data: Entities (210); Relationships (342)]. His vow to heed the Ghost of Christmas Future’s warnings [Data: Relationships (325)] and actions like purchasing a turkey [Data: Relationships (323)] signify a shift from greed to generosity. This transformation directly impacts the City’s social fabric, as Scrooge’s newfound empathy counteracts the societal indifference highlighted by the Ghost [Data: Entities (30); Relationships (14, 267)]."
        },
        {
            "summary": "Ghost of Christmas Yet to Come as a moral catalyst",
            "explanation": "The Ghost’s silent, foreboding revelations—including Scrooge’s neglected grave in the churchyard [Data: Entities (193); Relationships (315)]—force Scrooge to confront his mortality and legacy. These visions extend beyond personal fate to critique societal apathy toward poverty [Data: Entities (170, 171); Relationships (259, 265)]. The Ghost’s role is pivotal in linking Scrooge’s redemption to broader urban reform, as seen in the City’s dual portrayal of commerce and moral reckoning [Data: Entities (30); Relationships (273)]."
        },
        {
            "summary": "The City as a symbolic and literal setting",
            "explanation": "The City, modeled after Victorian London, reflects Scrooge’s emotional detachment through its foggy, bleak atmosphere [Data: Entities (30); Relationships (94)]. Post-redemption, Scrooge’s actions hint at transforming the City’s ethos, countering its portrayal as a hub of indifferent commerce [Data: Relationships (267)]. The Ghost’s vision of merchants persisting after Scrooge’s death underscores the urgency of his moral awakening to alter the City’s trajectory [Data: Entities (30); Relationships (14)]."
        },
        {
            "summary": "Jacob Marley’s ghost as a narrative catalyst",
            "explanation": "Marley’s ghost initiates Scrooge’s transformation by warning of impending spiritual reckoning [Data: Entities (61); Relationships (70)]. His chains symbolize the consequences of greed, directly paralleling Scrooge’s potential fate [Data: Relationships (70)]. This relationship establishes the stakes for Scrooge’s redemption, with Marley’s purgatorial torment serving as a cautionary template [Data: Relationships (73)]."
        },
        {
            "summary": "Allegorical figures (Ignorance and Want)",
            "explanation": "The Spirit reveals Ignorance and Want as embodiments of societal ills plaguing the City’s future [Data: Entities (170, 171); Relationships (259, 265)]. Their presence in Scrooge’s visions underscores the narrative’s critique of systemic poverty, linking his personal reform to broader societal change. These figures amplify the Ghost’s message, emphasizing that Scrooge’s choices impact collective welfare [Data: Relationships (267)]."
        },
        {
            "summary": "Childhood stories as escapism and moral contrast",
            "explanation": "Scrooge’s nostalgic recollections of fictional characters like Ali Baba and Robin Crusoe [Data: Entities (82, 86); Relationships (102, 107)] highlight his isolation and imaginative escape. These stories contrast with his adult miserliness, framing his redemption as a return to childhood empathy. The Parrot, symbolizing escapism [Data: Entities (89)], becomes a touchstone for Scrooge’s reconnection to human warmth."
        },
        {
            "summary": "Supernatural mechanisms driving transformation",
            "explanation": "The clock striking one triggers the Ghost’s visitation [Data: Entities (74); Relationships (90)], anchoring Scrooge’s supernatural experiences in precise temporal events. Wandering spirits outside his window [Data: Entities (198); Relationships (332, 333)] reinforce the narrative’s blending of reality and spectral intervention. These elements collectively pressure Scrooge to confront his moral decay [Data: Relationships (86)]."
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:58:47,950 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:58:47,950 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 0.0
15:58:50,582 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:58:50,592 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "The Ghost of Christmas Present and Ebenezer Scrooge Community",
    "summary": "This community centers on the Ghost of Christmas Present, Ebenezer Scrooge, and their transformative interactions within Charles Dickens' *A Christmas Carol*. Key entities include the Ghost, Scrooge, the Cratchit family, and the 1915 J.B. Lippincott-published edition of the novella. The Ghost’s role in exposing Scrooge to communal joy and societal issues drives the narrative, while ancillary entities like Great Britain, Philadelphia, and festive events (e.g., Christmas Morning) contextualize the story’s cultural and industrial critiques. Relationships emphasize the Ghost’s moral influence, Scrooge’s redemption arc, and the publisher’s role in disseminating the work.",
    "rating": 7.5,
    "rating_explanation": "The impact severity is high due to the enduring cultural influence of the story’s themes and its critique of industrialization and social inequality.",
    "findings": [
        {
            "summary": "Central role of the Ghost of Christmas Present",
            "explanation": "The Ghost of Christmas Present is the community’s core entity, symbolizing generosity and communal joy while challenging Scrooge’s worldview. Its interactions with Scrooge (Relationship 13), observations at Bakers’ Shops (Relationship 170), and blessing of the Cratchit home (Relationship 189) underscore its dual role as a festive figure and moral critic. The Ghost’s manifestation in Scrooge’s room (Entity 203, Relationship 331) reinforces its supernatural authority. [Data: Entities (12, 203); Relationships (13, 170, 189, 331)]"
        },
        {
            "summary": "Ebenezer Scrooge’s redemption arc",
            "explanation": "Scrooge’s transformation is the narrative backbone, driven by his interactions with the Ghost (Relationship 13) and the Visitation event (Relationship 160). His journey from isolation to empathy highlights themes of redemption and social responsibility, directly tied to Dickens’ critique of Victorian-era indifference. [Data: Entities (4); Relationships (8, 13, 160)]"
        },
        {
            "summary": "J.B. Lippincott Company’s publishing legacy",
            "explanation": "The J.B. Lippincott Company (Entity 3) published the 1915 illustrated edition of *A Christmas Carol*, with operations in Philadelphia (Relationship 5) and New York (Relationship 6). This entity connects the story’s literary impact to its physical dissemination, preserving Dickens’ work for future generations. [Data: Entities (3, 5, 6); Relationships (4, 5, 6)]"
        },
        {
            "summary": "Great Britain’s dual symbolic role",
            "explanation": "Great Britain (Entity 7) is both the printing location for the 1915 edition (Relationship 7) and a metaphor for industrial pollution in Dickens’ writing (Relationship 165). This duality reflects the novella’s blend of cultural preservation and social critique. [Data: Entities (7); Relationships (7, 165)]"
        },
        {
            "summary": "Christmas Morning’s festive and social contrasts",
            "explanation": "Christmas Morning (Entity 116) embodies holiday cheer through bustling grocers (Relationship 166) and Norfolk produce (Relationship 167), yet its sooty atmosphere (linked to Great Britain’s chimneys in Relationship 165) critiques industrialization. This juxtaposition underscores Dickens’ themes of inequality. [Data: Entities (116, 118, 117); Relationships (165, 166, 167)]"
        },
        {
            "summary": "Cratchit family’s symbolic significance",
            "explanation": "The Cratchit family dwelling (Entity 133) is blessed by the Ghost (Relationship 189), representing resilience and joy amid poverty. Their humble home contrasts with Scrooge’s wealth, emphasizing the story’s moral urgency. [Data: Entities (133); Relationships (189)]"
        },
        {
            "summary": "Scrooge’s niece as a festive catalyst",
            "explanation": "Scrooge’s niece (Entity 152) excels at games like Forfeits (Relationship 241) and 'How, When, and Where' (Relationship 242), symbolizing familial warmth and communal bonding. Her role during gatherings highlights the human connections Scrooge initially rejects. [Data: Entities (152, 157); Relationships (241, 242)]"
        },
        {
            "summary": "Arthur Rackham’s illustrative contributions",
            "explanation": "Arthur Rackham (Entity 2) illustrated the 1915 edition (Relationship 3), enhancing the novella’s visual legacy. His artwork complements Dickens’ themes, ensuring the story’s continued relevance. [Data: Entities (2); Relationships (3)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:58:50,599 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:58:50,599 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 4.0
15:58:57,227 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:59:00,172 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:59:00,182 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Ebenezer Scrooge, Jacob Marley, and Scrooge and Marley's Firm",
    "summary": "The community centers on Ebenezer Scrooge, his deceased business partner Jacob Marley, and their firm Scrooge and Marley. Scrooge’s miserly governance of the firm and his interactions with entities like Marley’s Ghost, his nephew Fred, and his underpaid Clerk drive the narrative. Marley’s spectral intervention catalyzes Scrooge’s transformation from a symbol of greed to benevolence, impacting his relationships with employees, family, and institutions like workhouses.",
    "rating": 7.5,
    "rating_explanation": "The impact severity is high due to Scrooge’s influence over employee welfare, social policies, and the transformative ripple effects of his redemption.",
    "findings": [
        {
            "summary": "Scrooge’s role as a miserly businessman",
            "explanation": "Ebenezer Scrooge is the linchpin of the community, operating Scrooge and Marley’s firm with ruthless frugality. He underpays his Clerk, endorses oppressive institutions like workhouses and prisons, and dismisses charitable appeals [Data: Entities (16, 28, 40, 41, 42); Relationships (44, 45, 46, 49, 50)]. His policies reflect Victorian-era exploitation, directly impacting the poor and his employees."
        },
        {
            "summary": "Marley’s Ghost as a catalyst for change",
            "explanation": "Jacob Marley’s ghost initiates Scrooge’s redemption by warning him of eternal torment unless he reforms. Marley’s chains symbolize their shared greed, and his intervention ties their fates together [Data: Entities (17, 25); Relationships (15, 19, 84)]. This spectral relationship underscores the moral consequences of their business practices."
        },
        {
            "summary": "Legacy of Scrooge and Marley’s Firm",
            "explanation": "The firm, retaining Marley’s name posthumously, symbolizes Scrooge’s entrenched avarice. Its operations in the City of London reflect industrial-era capitalism’s dehumanizing effects [Data: Entities (18, 19, 58); Relationships (21, 59)]. The firm’s name and location anchor the community’s critique of unchecked greed."
        },
        {
            "summary": "Fred’s role in humanizing Scrooge",
            "explanation": "Scrooge’s nephew Fred challenges his uncle’s misanthropy through the 'Yes and No Game,' which humorously exposes Scrooge’s isolation. Fred’s persistent kindness contrasts with Scrooge’s initial hostility [Data: Entities (168); Relationships (38, 247)]. This dynamic highlights familial bonds as a counterforce to greed."
        },
        {
            "summary": "The Clerk’s exploitation and resilience",
            "explanation": "Scrooge’s Clerk endures freezing conditions and job insecurity but maintains dignity. His quiet resilience and warmth toward Fred exemplify the human cost of Scrooge’s policies [Data: Entities (28); Relationships (31)]. His character underscores the story’s themes of empathy amid systemic neglect."
        },
        {
            "summary": "Endorsement of oppressive institutions",
            "explanation": "Scrooge actively supports workhouses, prisons, and the Poor Law, advocating them as solutions for poverty. These institutions symbolize societal indifference, amplified by his influence [Data: Entities (40, 41, 42, 54); Relationships (44, 45, 46)]. Their operational vigor reflects systemic neglect of the poor."
        },
        {
            "summary": "Scrooge’s transformation and its impact",
            "explanation": "After confronting his past, present, and future, Scrooge adopts generosity, raising the Clerk’s salary, aiding the Cratchits, and reconciling with Fred. This shift from exploitation to benevolence alters the community’s social fabric [Data: Entities (16); Relationships (336, 76, +more)]. His redemption illustrates the potential for systemic change through individual action."
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:59:00,191 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:59:00,191 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 11.0
15:59:02,81 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:59:02,90 graphrag.index.operations.summarize_communities.community_reports_extractor ERROR error generating community report
Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 126, in _parse_json_string
    return json.loads(value) if value else None
           ^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 346, in loads
    return _default_decoder.decode(s)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 337, in decode
    obj, end = self.raw_decode(s, idx=_w(s, 0).end())
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/decoder.py", line 355, in raw_decode
    raise JSONDecodeError("Expecting value", s, err.value) from None
json.decoder.JSONDecodeError: Expecting value: line 3 column 1 (char 2)

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 96, in invoke_json
    return await self.try_receive_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 114, in try_receive_json
    raw_json = self._parse_json_string(json_string)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 129, in _parse_json_string
    raise FailedToGenerateValidJsonError(msg) from err
fnllm.base.services.errors.FailedToGenerateValidJsonError: JSON response is not a valid JSON, response=

```json
{
    "title": "Jacob Marley and the Three Spirits Redemption Network",
    "summary": "The community centers on Jacob Marley, whose posthumous intervention via the Three Spirits drives Ebenezer Scrooge's moral transformation. Key entities include Marley’s ghost, the Three Spirits (First, Second, and Third), and events like Marley’s death and the Christmas Eve reckoning. Relationships highlight Marley’s orchestration of supernatural interventions, Scrooge’s ownership of their shared counting-house, and merchants’ cynical discussions of Marley’s legacy. The network bridges earthly greed (counting-house, merchants) and spiritual accountability (ghosts, spirits).",
    "rating": 7.5,
    "rating_explanation": "The high impact severity reflects existential stakes for Scrooge’s soul and broader societal implications of unchecked greed.",
    "findings": [
        {
            "summary": "Jacob Marley as spectral catalyst",
            "explanation": "Jacob Marley’s ghost serves as the community’s linchpin, directly connecting to Scrooge, the Three Spirits, and key events. His chains—explicitly tied to cash-boxes and ledgers—visually codify the consequences of greed, while his warning to Scrooge establishes the narrative’s moral framework. Marley’s influence persists posthumously through orchestrated spirit visitations and merchants’ discussions of his death and poorly attended funeral, underscoring his enduring impact. [Data: Entities (10, 197); Relationships (11, 271, 328, 329, +more)]"
        },
        {
            "summary": "Three Spirits as redemptive mechanism",
            "explanation": "The Three Spirits (First, Second, Third) form a structured intervention program designed by Marley to dismantle Scrooge’s misanthropy. Their sequential appearances—rigorously timed (One o’clock, 1 AM, midnight)—reflect a calculated psychological strategy targeting regret, empathy, and fear. The Second Spirit’s direct interaction with Scrooge exemplifies their role as moral interrogators. [Data: Entities (65, 66, 67, 68); Relationships (81, 82, 83)]"
        },
        {
            "summary": "Christmas Eve as temporal anchor",
            "explanation": "Christmas Eve simultaneously marks Marley’s death anniversary, Scrooge’s confrontation with supernatural forces, and Cratchit’s fleeting joy. This convergence transforms the date into a liminal space where past misdeeds (Marley’s chains), present cruelty (Scrooge’s rejection of Fred), and future redemption intersect. The cold weather mirrors Scrooge’s emotional state, while Cratchit’s sliding down Cornhill foreshadows potential warmth. [Data: Entities (31); Relationships (11, 33)]"
        },
        {
            "summary": "Merchants as societal mirror",
            "explanation": "Merchants at The Exchange embody societal indifference, mocking Marley’s funeral attendance and speculating about his wealth bequeathed to Marley’s Company. Their cynicism contrasts with the spirits’ moral urgency, highlighting widespread ethical decay. The Phantom’s use of their conversations as teaching tools for Scrooge positions them as a microcosm of systemic greed. [Data: Entities (178); Relationships (274, 275, 271)]"
        },
        {
            "summary": "Counting-house as greed symbol",
            "explanation": "The counting-house, now solely operated by Scrooge, physically embodies the community’s profit-over-people ethos. Its focus on financial transactions (money-changing) directly ties to Marley’s chains and Scrooge’s initial refusal to donate to charity. As the site where Scrooge dismisses Fred and begrudges Cratchit’s holiday, it anchors the narrative’s critique of industrial-era capitalism. [Data: Entities (63); Relationships (74)]"
        },
        {
            "summary": "Supernatural mechanics of redemption",
            "explanation": "The Ghost of Jacob Marley and the Phantom employ tangible haunting methods: emerging through a fireplace, transforming into a bedpost, and projecting visions of Marley’s death. These concrete manifestations bridge abstract moral themes (guilt, mortality) with visceral experience, forcing Scrooge’s engagement. The bedpost transformation particularly blurs reality and vision, destabilizing Scrooge’s rationality. [Data: Entities (173, 202, 207); Relationships (328, 329, 269)]"
        }
    ]
}
```.

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 144, in __call__
    return await self._decorated_target(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 77, in invoke
    return await this.invoke_json(delegate, prompt, kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/services/json.py", line 100, in invoke_json
    raise FailedToGenerateValidJsonError from error
fnllm.base.services.errors.FailedToGenerateValidJsonError

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/index/operations/summarize_communities/community_reports_extractor.py", line 80, in __call__
    response = await self._model.achat(
               ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/models.py", line 82, in achat
    response = await self.model(prompt, **kwargs)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/llm/openai_chat_llm.py", line 94, in __call__
    return await self._text_chat_llm(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/openai/services/openai_tools_parsing.py", line 130, in __call__
    return await self._delegate(prompt, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/fnllm/base/base_llm.py", line 148, in __call__
    await self._events.on_error(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/events.py", line 26, in on_error
    self._on_error(error, traceback, arguments)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/language_model/providers/fnllm/utils.py", line 45, in on_error
    callbacks.error("Error Invoking LLM", error, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/workflow_callbacks_manager.py", line 64, in error
    callback.error(message, cause, stack, details)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/site-packages/graphrag/callbacks/file_workflow_callbacks.py", line 37, in error
    json.dumps(
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/__init__.py", line 238, in dumps
    **kw).encode(obj)
          ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 202, in encode
    chunks = list(chunks)
             ^^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 432, in _iterencode
    yield from _iterencode_dict(o, _current_indent_level)
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 406, in _iterencode_dict
    yield from chunks
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 439, in _iterencode
    o = _default(o)
        ^^^^^^^^^^^
  File "/Users/pandegong/.pyenv/versions/3.12.1/lib/python3.12/json/encoder.py", line 180, in default
    raise TypeError(f'Object of type {o.__class__.__name__} '
TypeError: Object of type ModelMetaclass is not JSON serializable
15:59:02,99 graphrag.callbacks.file_workflow_callbacks INFO Community Report Extraction Error details=None
15:59:02,99 graphrag.index.operations.summarize_communities.strategies WARNING No report found for community: 2.0
15:59:04,618 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:59:07,272 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/chat/completions "HTTP/1.1 200 OK"
15:59:07,371 graphrag.utils.storage INFO reading table from storage: documents.parquet
15:59:07,374 graphrag.utils.storage INFO reading table from storage: relationships.parquet
15:59:07,377 graphrag.utils.storage INFO reading table from storage: text_units.parquet
15:59:07,379 graphrag.utils.storage INFO reading table from storage: entities.parquet
15:59:07,381 graphrag.utils.storage INFO reading table from storage: community_reports.parquet
15:59:07,384 graphrag.index.workflows.generate_text_embeddings INFO Creating embeddings
15:59:07,384 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding text_unit.text: default-text_unit-text
15:59:07,633 graphrag.index.operations.embed_text.strategies.openai INFO embedding 42 inputs via 42 snippets using 7 batches. max_batch_size=16, batch_max_tokens=8191
15:59:08,28 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,38 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,58 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,79 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,86 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,99 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,442 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,578 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding entity.description: default-entity-description
15:59:08,598 graphrag.index.operations.embed_text.strategies.openai INFO embedding 222 inputs via 222 snippets using 14 batches. max_batch_size=16, batch_max_tokens=8191
15:59:08,735 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,744 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,761 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,772 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,780 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,780 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,813 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,885 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,895 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,910 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,910 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,912 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,953 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:08,954 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:09,173 graphrag.index.operations.embed_text.embed_text INFO using vector store lancedb with container_name default for embedding community.full_content: default-community-full_content
15:59:09,183 graphrag.index.operations.embed_text.strategies.openai INFO embedding 27 inputs via 27 snippets using 2 batches. max_batch_size=16, batch_max_tokens=8191
15:59:09,495 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:09,571 httpx INFO HTTP Request: POST https://ark.cn-beijing.volces.com/api/v3/embeddings "HTTP/1.1 200 OK"
15:59:09,747 graphrag.cli.index INFO All workflows completed successfully.
